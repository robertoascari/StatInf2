[
  {
    "objectID": "Script5.html",
    "href": "Script5.html",
    "title": "Script 1 - Bernoulli - Beta",
    "section": "",
    "text": "You can download the R script here.\nIn this section, we will explore the Bernoulli-Beta model applied to the cardiac dataset. Specifically, we assume that \\(Y_i | \\theta \\sim Bernoulli(\\theta)\\) and that \\(\\theta \\sim Beta(a, b)\\). With these choices, we showed that the posterior distribution is \\(\\theta | \\textbf{y} \\sim Beta(a + \\sum_{i=1}^n y_i, b + n - \\sum_{i=1}^n y_i)\\).\nWe will examine four different scenarios, each corresponding to a distinct choice of hyperparameters for the Beta prior.\n\ncardiac &lt;- read.table(\"data/cardiac.csv\", header=T, sep=\";\")\nstr(cardiac)\n\n'data.frame':   100 obs. of  2 variables:\n $ Age: int  20 23 24 25 25 26 26 28 28 29 ...\n $ Chd: int  0 0 0 0 1 0 0 0 0 0 ...\n\ny &lt;- cardiac$Chd\ntable(y)\n\ny\n 0  1 \n57 43 \n\nsum(y)\n\n[1] 43\n\nlength(y)\n\n[1] 100\n\n\nThese are thw four scenarios we consider: - A: \\(\\theta \\sim Beta(1,1)\\); - B: \\(\\theta \\sim Beta(10,10)\\); - C: \\(\\theta \\sim Beta(10,5)\\); - D: \\(\\theta \\sim Beta(5,10)\\).\n\npar(mfrow=c(2,2))\ncurve(dbeta(x, 1, 1), main=\"Scenario A\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 10), main=\"Scenario B\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 5), main=\"Scenario C\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 5, 10), main=\"Scenario D\", xlab=expression(theta), ylab=expression(pi(theta)))\n\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\nWe further define the L_binom function, which returns the value of the likelihood function evaluated in a specific theta point.\n\nL_Binom &lt;- function(y, theta){\n  s &lt;- sum(y)\n  n &lt;- length(y)\n  L &lt;- theta^s * (1-theta)^(n-s)\n  return(L)\n}\n\nL_Binom(y, theta=0.001)\n\n[1] 9.445671e-130\n\n\nObviously, the likelihood function does not depend on the prior distribution we impose on \\(\\theta\\). In this case, the MLE corresponds to the sample mean (blue dashed line).\n\ncurve(L_Binom(y, theta=x), main=\"Likelihood\",\n      xlab=expression(theta), lwd=2)\nabline(v=mean(y), col=\"blue\", lty=\"dashed\")\n\n\n\n\n\n\n\n\n\nScenario A:\nIn this scenario, the prior distribution coincides with a uniform distribution on the \\((0,1)\\) interval. Thus, the prior mean (red dashed line) is equal to 0.5.\n\na1 &lt;- 1; b1 &lt;- 1\n\ncurve(dbeta(x, a1, b1), main=\"Prior A\", ylim=c(0,1.4),\n      xlab=expression(theta), lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\")\n\n\n\n\n\n\n\n\nThe posterior distribution is $| Beta()\n\nn &lt;- length(y)\na1.post &lt;- a1 + sum(y)\nb1.post &lt;- b1 + n - sum(y)\n\ncurve(dbeta(x, a1.post, b1.post), main=\"Scenario A\",\n      xlab=expression(theta), lwd=2)\ncurve(dbeta(x, a1, b1), lty=\"dashed\", add=T, lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\", lwd=2)\nabline(v=mean(y), col=\"green\", lty=\"dotted\", lwd=2)\nabline(v=a1.post/(a1.post+b1.post), col=\"blue\", lty=\"dashed\", lwd=2)\nlegend(.8,8, c(\"Prior\", \"Posterior\", \"Prior Mean\", \"MLE\", \"Post. Mean\"), lwd=2,\n       col=c(\"black\", \"black\", \"red\", \"green\", \"blue\"), lty=c(2,1,2,3,2), bty=\"n\")\n\n\n\n\n\n\n\n\n\n\nThe chosen prior distribution does not favor\n\n\nany value of theta.\n\n\nThus, we selected a non-informative prior.\n\n\nThe posterior distribution is centered\n\n\naround the MLE.\n\n\nScenario B:\na2 &lt;- 10; b2 &lt;- 10\n\n\nPrior distribution:\ncurve(dbeta(x, a2, b2), main=“Prior B”, xlab=expression(theta), lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”)\n\n\nLikelihood function:\ncurve(L_Binom(y, theta=x), main=“Likelihood”, xlab=expression(theta), lwd=2) abline(v=mean(y), col=“blue”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a2.post &lt;- a2 + sum(y) b2.post &lt;- b2 + n - sum(y)\ncurve(dbeta(x, a2.post, b2.post), main=“Scenario B”, xlab=expression(theta), lwd=2) curve(dbeta(x, a2, b2), lty=“dashed”, add=T, lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a2.post/(a2.post+b2.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nNow we are still considering a symmetric prior\n\n\nwith prior mean = 0.5, but it does not\n\n\ngive same density/probability to each\n\n\nvalue/interval of theta.\n\n\nNow the posterior mean is a weighted average\n\n\nbetween prior mean and MLE.\n\n\nScenario C:\na3 &lt;- 10; b3 &lt;- 5\n\n\nPosterior distribution:\nn &lt;- length(y) a3.post &lt;- a3 + sum(y) b3.post &lt;- b3 + n - sum(y)\ncurve(dbeta(x, a3.post, b3.post), main=“Scenario C”, xlab=expression(theta), lwd=2) curve(dbeta(x, a3, b3), lty=“dashed”, add=T, lwd=2) abline(v=a3/(a3+b3), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a3.post/(a3.post+b3.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nScenario D:\na4 &lt;- 5; b4 &lt;- 10\n\n\nPosterior distribution:\nn &lt;- length(y) a4.post &lt;- a4 + sum(y) b4.post &lt;- b4 + n - sum(y)\ncurve(dbeta(x, a4.post, b4.post), main=“Scenario D”, xlab=expression(theta), lwd=2) curve(dbeta(x, a4, b4), lty=“dashed”, add=T, lwd=2) abline(v=a4/(a4+b4), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a4.post/(a4.post+b4.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nWe may summarize the (prior and) posterior distribution\n\n\nby some measures:\nBeta.Exp &lt;- function(a, b) a/(a+b) Beta.Var &lt;- function(a, b)(ab)/((a+b)^2(a+b+1)) Beta.Mode &lt;- function(a, b){ ifelse(a&gt;1 & b&gt;1, (a-1)/(a+b-2), NA) } Beta.Median &lt;- function(a, b) qbeta(.5, a, b)\nmeasures &lt;- matrix(NA, ncol=6, nrow=4) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post) for(i in 1:4){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nIn this simple scenario, even considering\n\n\ndifferent priors, we do not have posteriors\n\n\nleading to very different point estimates.\n\n\nThis is because the empirical evidence\n\n\n(i.e., our data) is much\n\n\nstronger than our prior belief.\n\n\nLet us consider an additional scenario where\n\n\nwe strongly believe that most people\n\n\ndo not have cardiovascular disease.\na5 &lt;- 100 b5 &lt;- 1000\n\n\nPrior distribution:\ncurve(dbeta(x, a5, b5), main=“Prior E”, xlab=expression(theta)) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a5.post &lt;- a5 + sum(y) b5.post &lt;- b5 + n - sum(y)\ncurve(dbeta(x, a5.post, b5.post), main=“Scenario E”, xlab=expression(theta), lwd=2) curve(dbeta(x, a5, b5), lty=“dashed”, add=T, lwd=2) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a5.post/(a5.post+b5.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,40, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\nmeasures &lt;- matrix(NA, ncol=6, nrow=5) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”, “E”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post,a5.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post,b5.post) for(i in 1:5){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nInterval Estimates:\n\n\nCredible Sets (CS).\n\n\nThe CS are very easy to compute. Indeed, we only have to compute\n\n\nquantiles of the posterior distribution.\n\n\nLet us consider scenario D:\na &lt;- a4.post b &lt;- b4.post\n\n\nScenario D:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\n\n\nCS of level 0.95\nCS &lt;- qbeta(c(0.025,0.975), a, b);CS abline(v=CS,lty=“dashed”, col=“blue”) legend(0.8,8,c(“Posterior”, “Credible Set”), lty=c(1,2), col=c(“black”, “blue”), bty=“n”)\n\n\nHighest posterior density (HPD):\n\n\nLet’s start by considering a random value for h\nh &lt;- 2 curve(dbeta(x, a, b), ylab=expression(paste(pi,“(”,theta,“|x)”)), xlab=expression(theta)) abline(h=h,lty=2)\n\n\nWe need to find the values of theta such that p(theta|y) = h\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h # We decrease the density curve by h. # Now, the values we are looking for are such that translated = 0\ncurve(translated(x, a, b), add=T,lty=3,lwd=2) abline(h=0,lty=3)\nhpd1 &lt;- uniroot(translated,c(.2, .4),a,b)\\(root;hpd1\nhpd2 &lt;- uniroot(translated,c(.45, .5),a,b)\\)root;hpd2 integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)\n\n\nWe have a probability equal to 0.9152 –&gt; Decrease h\n\n\nIterative way:\nh.grid &lt;- seq(1, 2, by = 0.01)\nres &lt;- matrix(NA, ncol=4, nrow=length(h.grid)) colnames(res) &lt;- c(“HPD1”, “HPD2”, “level”, “h”)\nfor(i in 1:length(h.grid)){\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h.grid[i]\nhpd1&lt;-uniroot(translated,c(.2,.4),a,b)\\(root\n  hpd2&lt;-uniroot(translated,c(.43,.55),a,b)\\)root\nI &lt;- integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)$value\niter &lt;- i res[i,] &lt;- c(hpd1, hpd2, I, h.grid[i]) if(I &lt;= 0.95) break }\nres[1:iter,] h.grid[iter]\nHPD &lt;- res[iter-1,-c(3,4)]; HPD CS\n\n\nGraphically:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\nabline(v=CS,lty=“dashed”, col=“blue”) abline(v=HPD,lty=“dashed”, col=“red”)\nlegend(0.8,8,c(“Posterior”, “Credible Set”, “HPD”), lty=c(1,2,2), col=c(“black”, “blue”, “red”), bty=“n”)\n\n\nHPD and CS are very similar, because the posterior is\n\n\nunimodal and almost symmetrical.\n\n\nHypothesis testing:\n\n\nLet consider H0: theta &lt;= 0.3 vs H1: theta &gt; 0.3\npbeta(.3, a4, b4) pbeta(.3, a4.post, b4.post)\nODDS.prior &lt;- pbeta(.3, a4, b4)/(1-pbeta(.3, a4, b4)); ODDS.prior ODDS.post &lt;- pbeta(.3, a4.post, b4.post)/(1-pbeta(.3, a4.post, b4.post)); ODDS.post\nBayes_Factor &lt;- ODDS.post/ODDS.prior; Bayes_Factor\n\n\nData do not support H0: by adding data, our confidence on\n\n\nH0 strongly decreases\n\n\nHOMEWORK: consider a sample of size n = 10 composed of\n\n\nBernoulli trials, for which we observed s = 3 successes.\n\n\nConsider that a priori theta ~ Beta(2, 8)\n\n\n1. Which is the posterior distribution of theta?\n\n\n2. Compute the MLE and the prior and posterior means.\n\n\nAre these results reasonable?\n\n\n3. Compute and compare the CS and the HPD.\n\n\n4. Let H0 : theta in (0.3, 0.5)\n\n\nH1 : theta in (0, 0.3) U (0.5, 1)\n\n\nWhich hypothesis can you support?"
  },
  {
    "objectID": "Script3.html",
    "href": "Script3.html",
    "title": "Script 1 - Bernoulli - Beta",
    "section": "",
    "text": "You can download the R script here.\nIn this section, we will explore the Bernoulli-Beta model applied to the cardiac dataset. Specifically, we assume that \\(Y_i | \\theta \\sim Bernoulli(\\theta)\\) and that \\(\\theta \\sim Beta(a, b)\\). With these choices, we showed that the posterior distribution is \\(\\theta | \\textbf{y} \\sim Beta(a + \\sum_{i=1}^n y_i, b + n - \\sum_{i=1}^n y_i)\\).\nWe will examine four different scenarios, each corresponding to a distinct choice of hyperparameters for the Beta prior.\n\ncardiac &lt;- read.table(\"data/cardiac.csv\", header=T, sep=\";\")\nstr(cardiac)\n\n'data.frame':   100 obs. of  2 variables:\n $ Age: int  20 23 24 25 25 26 26 28 28 29 ...\n $ Chd: int  0 0 0 0 1 0 0 0 0 0 ...\n\ny &lt;- cardiac$Chd\ntable(y)\n\ny\n 0  1 \n57 43 \n\nsum(y)\n\n[1] 43\n\nlength(y)\n\n[1] 100\n\n\nThese are thw four scenarios we consider: - A: \\(\\theta \\sim Beta(1,1)\\); - B: \\(\\theta \\sim Beta(10,10)\\); - C: \\(\\theta \\sim Beta(10,5)\\); - D: \\(\\theta \\sim Beta(5,10)\\).\n\npar(mfrow=c(2,2))\ncurve(dbeta(x, 1, 1), main=\"Scenario A\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 10), main=\"Scenario B\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 5), main=\"Scenario C\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 5, 10), main=\"Scenario D\", xlab=expression(theta), ylab=expression(pi(theta)))\n\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\nWe further define the L_binom function, which returns the value of the likelihood function evaluated in a specific theta point.\n\nL_Binom &lt;- function(y, theta){\n  s &lt;- sum(y)\n  n &lt;- length(y)\n  L &lt;- theta^s * (1-theta)^(n-s)\n  return(L)\n}\n\nL_Binom(y, theta=0.001)\n\n[1] 9.445671e-130\n\n\nObviously, the likelihood function does not depend on the prior distribution we impose on \\(\\theta\\). In this case, the MLE corresponds to the sample mean (blue dashed line).\n\ncurve(L_Binom(y, theta=x), main=\"Likelihood\",\n      xlab=expression(theta), lwd=2)\nabline(v=mean(y), col=\"blue\", lty=\"dashed\")\n\n\n\n\n\n\n\n\n\nScenario A:\nIn this scenario, the prior distribution coincides with a uniform distribution on the \\((0,1)\\) interval. Thus, the prior mean (red dashed line) is equal to 0.5.\n\na1 &lt;- 1; b1 &lt;- 1\n\ncurve(dbeta(x, a1, b1), main=\"Prior A\", ylim=c(0,1.4),\n      xlab=expression(theta), lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\")\n\n\n\n\n\n\n\n\nThe posterior distribution is $| Beta()\n\nn &lt;- length(y)\na1.post &lt;- a1 + sum(y)\nb1.post &lt;- b1 + n - sum(y)\n\ncurve(dbeta(x, a1.post, b1.post), main=\"Scenario A\",\n      xlab=expression(theta), lwd=2)\ncurve(dbeta(x, a1, b1), lty=\"dashed\", add=T, lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\", lwd=2)\nabline(v=mean(y), col=\"green\", lty=\"dotted\", lwd=2)\nabline(v=a1.post/(a1.post+b1.post), col=\"blue\", lty=\"dashed\", lwd=2)\nlegend(.8,8, c(\"Prior\", \"Posterior\", \"Prior Mean\", \"MLE\", \"Post. Mean\"), lwd=2,\n       col=c(\"black\", \"black\", \"red\", \"green\", \"blue\"), lty=c(2,1,2,3,2), bty=\"n\")\n\n\n\n\n\n\n\n\n\n\nThe chosen prior distribution does not favor\n\n\nany value of theta.\n\n\nThus, we selected a non-informative prior.\n\n\nThe posterior distribution is centered\n\n\naround the MLE.\n\n\nScenario B:\na2 &lt;- 10; b2 &lt;- 10\n\n\nPrior distribution:\ncurve(dbeta(x, a2, b2), main=“Prior B”, xlab=expression(theta), lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”)\n\n\nLikelihood function:\ncurve(L_Binom(y, theta=x), main=“Likelihood”, xlab=expression(theta), lwd=2) abline(v=mean(y), col=“blue”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a2.post &lt;- a2 + sum(y) b2.post &lt;- b2 + n - sum(y)\ncurve(dbeta(x, a2.post, b2.post), main=“Scenario B”, xlab=expression(theta), lwd=2) curve(dbeta(x, a2, b2), lty=“dashed”, add=T, lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a2.post/(a2.post+b2.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nNow we are still considering a symmetric prior\n\n\nwith prior mean = 0.5, but it does not\n\n\ngive same density/probability to each\n\n\nvalue/interval of theta.\n\n\nNow the posterior mean is a weighted average\n\n\nbetween prior mean and MLE.\n\n\nScenario C:\na3 &lt;- 10; b3 &lt;- 5\n\n\nPosterior distribution:\nn &lt;- length(y) a3.post &lt;- a3 + sum(y) b3.post &lt;- b3 + n - sum(y)\ncurve(dbeta(x, a3.post, b3.post), main=“Scenario C”, xlab=expression(theta), lwd=2) curve(dbeta(x, a3, b3), lty=“dashed”, add=T, lwd=2) abline(v=a3/(a3+b3), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a3.post/(a3.post+b3.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nScenario D:\na4 &lt;- 5; b4 &lt;- 10\n\n\nPosterior distribution:\nn &lt;- length(y) a4.post &lt;- a4 + sum(y) b4.post &lt;- b4 + n - sum(y)\ncurve(dbeta(x, a4.post, b4.post), main=“Scenario D”, xlab=expression(theta), lwd=2) curve(dbeta(x, a4, b4), lty=“dashed”, add=T, lwd=2) abline(v=a4/(a4+b4), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a4.post/(a4.post+b4.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nWe may summarize the (prior and) posterior distribution\n\n\nby some measures:\nBeta.Exp &lt;- function(a, b) a/(a+b) Beta.Var &lt;- function(a, b)(ab)/((a+b)^2(a+b+1)) Beta.Mode &lt;- function(a, b){ ifelse(a&gt;1 & b&gt;1, (a-1)/(a+b-2), NA) } Beta.Median &lt;- function(a, b) qbeta(.5, a, b)\nmeasures &lt;- matrix(NA, ncol=6, nrow=4) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post) for(i in 1:4){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nIn this simple scenario, even considering\n\n\ndifferent priors, we do not have posteriors\n\n\nleading to very different point estimates.\n\n\nThis is because the empirical evidence\n\n\n(i.e., our data) is much\n\n\nstronger than our prior belief.\n\n\nLet us consider an additional scenario where\n\n\nwe strongly believe that most people\n\n\ndo not have cardiovascular disease.\na5 &lt;- 100 b5 &lt;- 1000\n\n\nPrior distribution:\ncurve(dbeta(x, a5, b5), main=“Prior E”, xlab=expression(theta)) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a5.post &lt;- a5 + sum(y) b5.post &lt;- b5 + n - sum(y)\ncurve(dbeta(x, a5.post, b5.post), main=“Scenario E”, xlab=expression(theta), lwd=2) curve(dbeta(x, a5, b5), lty=“dashed”, add=T, lwd=2) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a5.post/(a5.post+b5.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,40, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\nmeasures &lt;- matrix(NA, ncol=6, nrow=5) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”, “E”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post,a5.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post,b5.post) for(i in 1:5){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nInterval Estimates:\n\n\nCredible Sets (CS).\n\n\nThe CS are very easy to compute. Indeed, we only have to compute\n\n\nquantiles of the posterior distribution.\n\n\nLet us consider scenario D:\na &lt;- a4.post b &lt;- b4.post\n\n\nScenario D:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\n\n\nCS of level 0.95\nCS &lt;- qbeta(c(0.025,0.975), a, b);CS abline(v=CS,lty=“dashed”, col=“blue”) legend(0.8,8,c(“Posterior”, “Credible Set”), lty=c(1,2), col=c(“black”, “blue”), bty=“n”)\n\n\nHighest posterior density (HPD):\n\n\nLet’s start by considering a random value for h\nh &lt;- 2 curve(dbeta(x, a, b), ylab=expression(paste(pi,“(”,theta,“|x)”)), xlab=expression(theta)) abline(h=h,lty=2)\n\n\nWe need to find the values of theta such that p(theta|y) = h\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h # We decrease the density curve by h. # Now, the values we are looking for are such that translated = 0\ncurve(translated(x, a, b), add=T,lty=3,lwd=2) abline(h=0,lty=3)\nhpd1 &lt;- uniroot(translated,c(.2, .4),a,b)\\(root;hpd1\nhpd2 &lt;- uniroot(translated,c(.45, .5),a,b)\\)root;hpd2 integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)\n\n\nWe have a probability equal to 0.9152 –&gt; Decrease h\n\n\nIterative way:\nh.grid &lt;- seq(1, 2, by = 0.01)\nres &lt;- matrix(NA, ncol=4, nrow=length(h.grid)) colnames(res) &lt;- c(“HPD1”, “HPD2”, “level”, “h”)\nfor(i in 1:length(h.grid)){\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h.grid[i]\nhpd1&lt;-uniroot(translated,c(.2,.4),a,b)\\(root\n  hpd2&lt;-uniroot(translated,c(.43,.55),a,b)\\)root\nI &lt;- integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)$value\niter &lt;- i res[i,] &lt;- c(hpd1, hpd2, I, h.grid[i]) if(I &lt;= 0.95) break }\nres[1:iter,] h.grid[iter]\nHPD &lt;- res[iter-1,-c(3,4)]; HPD CS\n\n\nGraphically:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\nabline(v=CS,lty=“dashed”, col=“blue”) abline(v=HPD,lty=“dashed”, col=“red”)\nlegend(0.8,8,c(“Posterior”, “Credible Set”, “HPD”), lty=c(1,2,2), col=c(“black”, “blue”, “red”), bty=“n”)\n\n\nHPD and CS are very similar, because the posterior is\n\n\nunimodal and almost symmetrical.\n\n\nHypothesis testing:\n\n\nLet consider H0: theta &lt;= 0.3 vs H1: theta &gt; 0.3\npbeta(.3, a4, b4) pbeta(.3, a4.post, b4.post)\nODDS.prior &lt;- pbeta(.3, a4, b4)/(1-pbeta(.3, a4, b4)); ODDS.prior ODDS.post &lt;- pbeta(.3, a4.post, b4.post)/(1-pbeta(.3, a4.post, b4.post)); ODDS.post\nBayes_Factor &lt;- ODDS.post/ODDS.prior; Bayes_Factor\n\n\nData do not support H0: by adding data, our confidence on\n\n\nH0 strongly decreases\n\n\nHOMEWORK: consider a sample of size n = 10 composed of\n\n\nBernoulli trials, for which we observed s = 3 successes.\n\n\nConsider that a priori theta ~ Beta(2, 8)\n\n\n1. Which is the posterior distribution of theta?\n\n\n2. Compute the MLE and the prior and posterior means.\n\n\nAre these results reasonable?\n\n\n3. Compute and compare the CS and the HPD.\n\n\n4. Let H0 : theta in (0.3, 0.5)\n\n\nH1 : theta in (0, 0.3) U (0.5, 1)\n\n\nWhich hypothesis can you support?"
  },
  {
    "objectID": "Script1.html",
    "href": "Script1.html",
    "title": "Script 1 - Bernoulli - Beta",
    "section": "",
    "text": "You can download the R script here.\nIn this section, we will explore the Bernoulli-Beta model applied to the cardiac dataset. Specifically, we assume that \\(Y_i | \\theta \\sim Bernoulli(\\theta)\\) and that \\(\\theta \\sim Beta(a, b)\\). With these choices, we showed that the posterior distribution is \\[\\theta | \\textbf{y} \\sim Beta\\left(a + \\sum_{i=1}^n y_i, b + n - \\sum_{i=1}^n y_i\\right).\\]\nWe will examine four different scenarios, each corresponding to a distinct choice of hyperparameters for the Beta prior.\n\ncardiac &lt;- read.table(\"data/cardiac.csv\", header=T, sep=\";\")\nstr(cardiac)\n\n'data.frame':   100 obs. of  2 variables:\n $ Age: int  20 23 24 25 25 26 26 28 28 29 ...\n $ Chd: int  0 0 0 0 1 0 0 0 0 0 ...\n\ny &lt;- cardiac$Chd\ntable(y)\n\ny\n 0  1 \n57 43 \n\nsum(y)\n\n[1] 43\n\n\n\ncardiac &lt;- read.table(\"data/cardiac.csv\", header=T, sep=\";\")\nstr(cardiac)\n\n'data.frame':   100 obs. of  2 variables:\n $ Age: int  20 23 24 25 25 26 26 28 28 29 ...\n $ Chd: int  0 0 0 0 1 0 0 0 0 0 ...\n\ny &lt;- cardiac$Chd\ntable(y)\n\ny\n 0  1 \n57 43 \n\nsum(y)\n\n[1] 43\n\nlength(y)\n\n[1] 100\n\n\n\nsum(y)\n\n[1] 43\n\n\n\nlength(y)\n\n[1] 100\n\n\nThese are the four scenarios we consider: - A: \\(\\theta \\sim Beta(1,1)\\); - B: \\(\\theta \\sim Beta(10,10)\\); - C: \\(\\theta \\sim Beta(10,5)\\); - D: \\(\\theta \\sim Beta(5,10)\\).\n\npar(mfrow=c(2,2))\ncurve(dbeta(x, 1, 1), main=\"Scenario A\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 10), main=\"Scenario B\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 5), main=\"Scenario C\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 5, 10), main=\"Scenario D\", xlab=expression(theta), ylab=expression(pi(theta)))\n\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\nWe further define the L_binom function, which returns the value of the likelihood function evaluated in a specific theta point.\n\nL_Binom &lt;- function(y, theta){\n  s &lt;- sum(y)\n  n &lt;- length(y)\n  L &lt;- theta^s * (1-theta)^(n-s)\n  return(L)\n}\n\nL_Binom(y, theta=0.001)\n\n[1] 9.445671e-130\n\n\nObviously, the likelihood function does not depend on the prior distribution we impose on \\(\\theta\\). In this case, the MLE corresponds to the sample mean (blue dashed line).\n\ncurve(L_Binom(y, theta=x), main=\"Likelihood\",\n      xlab=expression(theta), lwd=2)\nabline(v=mean(y), col=\"blue\", lty=\"dashed\")\n\n\n\n\n\n\n\n\n\nScenario A:\nIn this scenario, the prior distribution coincides with a uniform distribution on the \\((0,1)\\) interval. Thus, the prior mean (red dashed line) is equal to 0.5.\n\na1 &lt;- 1; b1 &lt;- 1\n\ncurve(dbeta(x, a1, b1), main=\"Prior A\", ylim=c(0,1.4),\n      xlab=expression(theta), lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\")\n\n\n\n\n\n\n\n\nThe posterior distribution is $| Beta()\n\nn &lt;- length(y)\na1.post &lt;- a1 + sum(y)\nb1.post &lt;- b1 + n - sum(y)\n\ncurve(dbeta(x, a1.post, b1.post), main=\"Scenario A\",\n      xlab=expression(theta), lwd=2)\ncurve(dbeta(x, a1, b1), lty=\"dashed\", add=T, lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\", lwd=2)\nabline(v=mean(y), col=\"green\", lty=\"dotted\", lwd=2)\nabline(v=a1.post/(a1.post+b1.post), col=\"blue\", lty=\"dashed\", lwd=2)\nlegend(.8,8, c(\"Prior\", \"Posterior\", \"Prior Mean\", \"MLE\", \"Post. Mean\"), lwd=2,\n       col=c(\"black\", \"black\", \"red\", \"green\", \"blue\"), lty=c(2,1,2,3,2), bty=\"n\")\n\n\n\n\n\n\n\n\nThe chosen prior distribution does not favor any particular value of \\(\\theta\\). Thus, we selected a non-informative prior. As a result, the posterior distribution is centered around the maximum likelihood estimate (MLE).\n\n\nScenario B:\nIn this scenario, we use a prior distribution for \\(\\theta\\) that is still symmetric (meaning it treats values below and above 0.5 in the same way). However, unlike the uniform prior, it is not flat: it expresses a preference for values closer to 0.5.\n\na2 &lt;- 10; b2 &lt;- 10\n\ncurve(dbeta(x, a2, b2), main=\"Prior B\",\n      xlab=expression(theta), lwd=2)\nabline(v=a2/(a2+b2), col=\"red\", lty=\"dashed\")\n\n\n\n\n\n\n\n\n\nn &lt;- length(y)\na2.post &lt;- a2 + sum(y)\nb2.post &lt;- b2 + n - sum(y)\n\ncurve(dbeta(x, a2.post, b2.post), main=\"Scenario B\",\n      xlab=expression(theta), lwd=2)\ncurve(dbeta(x, a2, b2), lty=\"dashed\", add=T, lwd=2)\nabline(v=a2/(a2+b2), col=\"red\", lty=\"dashed\", lwd=2)\nabline(v=mean(y), col=\"green\", lty=\"dotted\", lwd=2)\nabline(v=a2.post/(a2.post+b2.post), col=\"blue\", lty=\"dashed\", lwd=2)\nlegend(.8,8, c(\"Prior\", \"Posterior\", \"Prior Mean\", \"MLE\", \"Post. Mean\"), lwd=2,\n       col=c(\"black\", \"black\", \"red\", \"green\", \"blue\"), lty=c(2,1,2,3,2), bty=\"n\")\n\n\n\n\n\n\n\n\nSince we are still considering a symmetric prior, the prior mean is equal to 0.5. However, unlike the uniform prior, it does not assign the same probability density to every value or interval of \\(\\theta\\). As a consequence, the posterior mean becomes a weighted average between the prior mean and the MLE.\n\n\nScenario C:\na3 &lt;- 10; b3 &lt;- 5\n\n\nPosterior distribution:\nn &lt;- length(y) a3.post &lt;- a3 + sum(y) b3.post &lt;- b3 + n - sum(y)\ncurve(dbeta(x, a3.post, b3.post), main=“Scenario C”, xlab=expression(theta), lwd=2) curve(dbeta(x, a3, b3), lty=“dashed”, add=T, lwd=2) abline(v=a3/(a3+b3), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a3.post/(a3.post+b3.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nScenario D:\na4 &lt;- 5; b4 &lt;- 10\n\n\nPosterior distribution:\nn &lt;- length(y) a4.post &lt;- a4 + sum(y) b4.post &lt;- b4 + n - sum(y)\ncurve(dbeta(x, a4.post, b4.post), main=“Scenario D”, xlab=expression(theta), lwd=2) curve(dbeta(x, a4, b4), lty=“dashed”, add=T, lwd=2) abline(v=a4/(a4+b4), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a4.post/(a4.post+b4.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nWe may summarize the (prior and) posterior distribution\n\n\nby some measures:\nBeta.Exp &lt;- function(a, b) a/(a+b) Beta.Var &lt;- function(a, b)(ab)/((a+b)^2(a+b+1)) Beta.Mode &lt;- function(a, b){ ifelse(a&gt;1 & b&gt;1, (a-1)/(a+b-2), NA) } Beta.Median &lt;- function(a, b) qbeta(.5, a, b)\nmeasures &lt;- matrix(NA, ncol=6, nrow=4) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post) for(i in 1:4){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nIn this simple scenario, even considering\n\n\ndifferent priors, we do not have posteriors\n\n\nleading to very different point estimates.\n\n\nThis is because the empirical evidence\n\n\n(i.e., our data) is much\n\n\nstronger than our prior belief.\n\n\nLet us consider an additional scenario where\n\n\nwe strongly believe that most people\n\n\ndo not have cardiovascular disease.\na5 &lt;- 100 b5 &lt;- 1000\n\n\nPrior distribution:\ncurve(dbeta(x, a5, b5), main=“Prior E”, xlab=expression(theta)) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a5.post &lt;- a5 + sum(y) b5.post &lt;- b5 + n - sum(y)\ncurve(dbeta(x, a5.post, b5.post), main=“Scenario E”, xlab=expression(theta), lwd=2) curve(dbeta(x, a5, b5), lty=“dashed”, add=T, lwd=2) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a5.post/(a5.post+b5.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,40, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\nmeasures &lt;- matrix(NA, ncol=6, nrow=5) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”, “E”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post,a5.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post,b5.post) for(i in 1:5){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nInterval Estimates:\n\n\nCredible Sets (CS).\n\n\nThe CS are very easy to compute. Indeed, we only have to compute\n\n\nquantiles of the posterior distribution.\n\n\nLet us consider scenario D:\na &lt;- a4.post b &lt;- b4.post\n\n\nScenario D:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\n\n\nCS of level 0.95\nCS &lt;- qbeta(c(0.025,0.975), a, b);CS abline(v=CS,lty=“dashed”, col=“blue”) legend(0.8,8,c(“Posterior”, “Credible Set”), lty=c(1,2), col=c(“black”, “blue”), bty=“n”)\n\n\nHighest posterior density (HPD):\n\n\nLet’s start by considering a random value for h\nh &lt;- 2 curve(dbeta(x, a, b), ylab=expression(paste(pi,“(”,theta,“|x)”)), xlab=expression(theta)) abline(h=h,lty=2)\n\n\nWe need to find the values of theta such that p(theta|y) = h\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h # We decrease the density curve by h. # Now, the values we are looking for are such that translated = 0\ncurve(translated(x, a, b), add=T,lty=3,lwd=2) abline(h=0,lty=3)\nhpd1 &lt;- uniroot(translated,c(.2, .4),a,b)\\(root;hpd1\nhpd2 &lt;- uniroot(translated,c(.45, .5),a,b)\\)root;hpd2 integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)\n\n\nWe have a probability equal to 0.9152 –&gt; Decrease h\n\n\nIterative way:\nh.grid &lt;- seq(1, 2, by = 0.01)\nres &lt;- matrix(NA, ncol=4, nrow=length(h.grid)) colnames(res) &lt;- c(“HPD1”, “HPD2”, “level”, “h”)\nfor(i in 1:length(h.grid)){\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h.grid[i]\nhpd1&lt;-uniroot(translated,c(.2,.4),a,b)\\(root\n  hpd2&lt;-uniroot(translated,c(.43,.55),a,b)\\)root\nI &lt;- integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)$value\niter &lt;- i res[i,] &lt;- c(hpd1, hpd2, I, h.grid[i]) if(I &lt;= 0.95) break }\nres[1:iter,] h.grid[iter]\nHPD &lt;- res[iter-1,-c(3,4)]; HPD CS\n\n\nGraphically:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\nabline(v=CS,lty=“dashed”, col=“blue”) abline(v=HPD,lty=“dashed”, col=“red”)\nlegend(0.8,8,c(“Posterior”, “Credible Set”, “HPD”), lty=c(1,2,2), col=c(“black”, “blue”, “red”), bty=“n”)\n\n\nHPD and CS are very similar, because the posterior is\n\n\nunimodal and almost symmetrical.\n\n\nHypothesis testing:\n\n\nLet consider H0: theta &lt;= 0.3 vs H1: theta &gt; 0.3\npbeta(.3, a4, b4) pbeta(.3, a4.post, b4.post)\nODDS.prior &lt;- pbeta(.3, a4, b4)/(1-pbeta(.3, a4, b4)); ODDS.prior ODDS.post &lt;- pbeta(.3, a4.post, b4.post)/(1-pbeta(.3, a4.post, b4.post)); ODDS.post\nBayes_Factor &lt;- ODDS.post/ODDS.prior; Bayes_Factor\n\n\nData do not support H0: by adding data, our confidence on\n\n\nH0 strongly decreases\n\n\nHOMEWORK: consider a sample of size n = 10 composed of\n\n\nBernoulli trials, for which we observed s = 3 successes.\n\n\nConsider that a priori theta ~ Beta(2, 8)\n\n\n1. Which is the posterior distribution of theta?\n\n\n2. Compute the MLE and the prior and posterior means.\n\n\nAre these results reasonable?\n\n\n3. Compute and compare the CS and the HPD.\n\n\n4. Let H0 : theta in (0.3, 0.5)\n\n\nH1 : theta in (0, 0.3) U (0.5, 1)\n\n\nWhich hypothesis can you support?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Inference II",
    "section": "",
    "text": "Statistical Inference II provides an introduction to Bayesian data analysis, covering prior and posterior distributions, classical one-parameter models, prior elicitation, posterior-based inference, MCMC methods, and Bayesian approaches to linear and generalized linear models."
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Statistical Inference II",
    "section": "Syllabus",
    "text": "Syllabus\n\nIntroduction to Bayesian data analysis: prior and posterior distributions for inference.\nOne-parameter models: Binomial-Beta, Poisson-Gamma, Exponential-Gamma, and Normal-Normal.\nMethods for prior elicitation.\nInference based on the posterior distribution (point and interval estimates; hypotheses testing).\nSimulation-based inference: MCMC methods.\nLinear and generalized linear models from a Bayesian perspective."
  },
  {
    "objectID": "index.html#textbooks",
    "href": "index.html#textbooks",
    "title": "Statistical Inference II",
    "section": "Textbooks",
    "text": "Textbooks\n\nHoff, P. (2009). A first course in Bayesian Statistical Methods. Springer.\nGelman, A., Carlin, J., Stern, H., Dunson, D., Vehtari, A., and Rubin, D. (2013). Bayesian Data Analysis. Chapman & Hall/CRC Texts in Statistical Science.\nRobert, C. and Casella, G. (2004). Monte Carlo Statistical Methods. Springer."
  },
  {
    "objectID": "Script2.html",
    "href": "Script2.html",
    "title": "Script 1 - Bernoulli - Beta",
    "section": "",
    "text": "You can download the R script here.\nIn this section, we will explore the Bernoulli-Beta model applied to the cardiac dataset. Specifically, we assume that \\(Y_i | \\theta \\sim Bernoulli(\\theta)\\) and that \\(\\theta \\sim Beta(a, b)\\). With these choices, we showed that the posterior distribution is \\(\\theta | \\textbf{y} \\sim Beta(a + \\sum_{i=1}^n y_i, b + n - \\sum_{i=1}^n y_i)\\).\nWe will examine four different scenarios, each corresponding to a distinct choice of hyperparameters for the Beta prior.\n\ncardiac &lt;- read.table(\"data/cardiac.csv\", header=T, sep=\";\")\nstr(cardiac)\n\n'data.frame':   100 obs. of  2 variables:\n $ Age: int  20 23 24 25 25 26 26 28 28 29 ...\n $ Chd: int  0 0 0 0 1 0 0 0 0 0 ...\n\ny &lt;- cardiac$Chd\ntable(y)\n\ny\n 0  1 \n57 43 \n\nsum(y)\n\n[1] 43\n\nlength(y)\n\n[1] 100\n\n\nThese are thw four scenarios we consider: - A: \\(\\theta \\sim Beta(1,1)\\); - B: \\(\\theta \\sim Beta(10,10)\\); - C: \\(\\theta \\sim Beta(10,5)\\); - D: \\(\\theta \\sim Beta(5,10)\\).\n\npar(mfrow=c(2,2))\ncurve(dbeta(x, 1, 1), main=\"Scenario A\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 10), main=\"Scenario B\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 5), main=\"Scenario C\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 5, 10), main=\"Scenario D\", xlab=expression(theta), ylab=expression(pi(theta)))\n\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\nWe further define the L_binom function, which returns the value of the likelihood function evaluated in a specific theta point.\n\nL_Binom &lt;- function(y, theta){\n  s &lt;- sum(y)\n  n &lt;- length(y)\n  L &lt;- theta^s * (1-theta)^(n-s)\n  return(L)\n}\n\nL_Binom(y, theta=0.001)\n\n[1] 9.445671e-130\n\n\nObviously, the likelihood function does not depend on the prior distribution we impose on \\(\\theta\\). In this case, the MLE corresponds to the sample mean (blue dashed line).\n\ncurve(L_Binom(y, theta=x), main=\"Likelihood\",\n      xlab=expression(theta), lwd=2)\nabline(v=mean(y), col=\"blue\", lty=\"dashed\")\n\n\n\n\n\n\n\n\n\nScenario A:\nIn this scenario, the prior distribution coincides with a uniform distribution on the \\((0,1)\\) interval. Thus, the prior mean (red dashed line) is equal to 0.5.\n\na1 &lt;- 1; b1 &lt;- 1\n\ncurve(dbeta(x, a1, b1), main=\"Prior A\", ylim=c(0,1.4),\n      xlab=expression(theta), lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\")\n\n\n\n\n\n\n\n\nThe posterior distribution is $| Beta()\n\nn &lt;- length(y)\na1.post &lt;- a1 + sum(y)\nb1.post &lt;- b1 + n - sum(y)\n\ncurve(dbeta(x, a1.post, b1.post), main=\"Scenario A\",\n      xlab=expression(theta), lwd=2)\ncurve(dbeta(x, a1, b1), lty=\"dashed\", add=T, lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\", lwd=2)\nabline(v=mean(y), col=\"green\", lty=\"dotted\", lwd=2)\nabline(v=a1.post/(a1.post+b1.post), col=\"blue\", lty=\"dashed\", lwd=2)\nlegend(.8,8, c(\"Prior\", \"Posterior\", \"Prior Mean\", \"MLE\", \"Post. Mean\"), lwd=2,\n       col=c(\"black\", \"black\", \"red\", \"green\", \"blue\"), lty=c(2,1,2,3,2), bty=\"n\")\n\n\n\n\n\n\n\n\n\n\nThe chosen prior distribution does not favor\n\n\nany value of theta.\n\n\nThus, we selected a non-informative prior.\n\n\nThe posterior distribution is centered\n\n\naround the MLE.\n\n\nScenario B:\na2 &lt;- 10; b2 &lt;- 10\n\n\nPrior distribution:\ncurve(dbeta(x, a2, b2), main=“Prior B”, xlab=expression(theta), lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”)\n\n\nLikelihood function:\ncurve(L_Binom(y, theta=x), main=“Likelihood”, xlab=expression(theta), lwd=2) abline(v=mean(y), col=“blue”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a2.post &lt;- a2 + sum(y) b2.post &lt;- b2 + n - sum(y)\ncurve(dbeta(x, a2.post, b2.post), main=“Scenario B”, xlab=expression(theta), lwd=2) curve(dbeta(x, a2, b2), lty=“dashed”, add=T, lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a2.post/(a2.post+b2.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nNow we are still considering a symmetric prior\n\n\nwith prior mean = 0.5, but it does not\n\n\ngive same density/probability to each\n\n\nvalue/interval of theta.\n\n\nNow the posterior mean is a weighted average\n\n\nbetween prior mean and MLE.\n\n\nScenario C:\na3 &lt;- 10; b3 &lt;- 5\n\n\nPosterior distribution:\nn &lt;- length(y) a3.post &lt;- a3 + sum(y) b3.post &lt;- b3 + n - sum(y)\ncurve(dbeta(x, a3.post, b3.post), main=“Scenario C”, xlab=expression(theta), lwd=2) curve(dbeta(x, a3, b3), lty=“dashed”, add=T, lwd=2) abline(v=a3/(a3+b3), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a3.post/(a3.post+b3.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nScenario D:\na4 &lt;- 5; b4 &lt;- 10\n\n\nPosterior distribution:\nn &lt;- length(y) a4.post &lt;- a4 + sum(y) b4.post &lt;- b4 + n - sum(y)\ncurve(dbeta(x, a4.post, b4.post), main=“Scenario D”, xlab=expression(theta), lwd=2) curve(dbeta(x, a4, b4), lty=“dashed”, add=T, lwd=2) abline(v=a4/(a4+b4), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a4.post/(a4.post+b4.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nWe may summarize the (prior and) posterior distribution\n\n\nby some measures:\nBeta.Exp &lt;- function(a, b) a/(a+b) Beta.Var &lt;- function(a, b)(ab)/((a+b)^2(a+b+1)) Beta.Mode &lt;- function(a, b){ ifelse(a&gt;1 & b&gt;1, (a-1)/(a+b-2), NA) } Beta.Median &lt;- function(a, b) qbeta(.5, a, b)\nmeasures &lt;- matrix(NA, ncol=6, nrow=4) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post) for(i in 1:4){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nIn this simple scenario, even considering\n\n\ndifferent priors, we do not have posteriors\n\n\nleading to very different point estimates.\n\n\nThis is because the empirical evidence\n\n\n(i.e., our data) is much\n\n\nstronger than our prior belief.\n\n\nLet us consider an additional scenario where\n\n\nwe strongly believe that most people\n\n\ndo not have cardiovascular disease.\na5 &lt;- 100 b5 &lt;- 1000\n\n\nPrior distribution:\ncurve(dbeta(x, a5, b5), main=“Prior E”, xlab=expression(theta)) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a5.post &lt;- a5 + sum(y) b5.post &lt;- b5 + n - sum(y)\ncurve(dbeta(x, a5.post, b5.post), main=“Scenario E”, xlab=expression(theta), lwd=2) curve(dbeta(x, a5, b5), lty=“dashed”, add=T, lwd=2) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a5.post/(a5.post+b5.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,40, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\nmeasures &lt;- matrix(NA, ncol=6, nrow=5) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”, “E”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post,a5.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post,b5.post) for(i in 1:5){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nInterval Estimates:\n\n\nCredible Sets (CS).\n\n\nThe CS are very easy to compute. Indeed, we only have to compute\n\n\nquantiles of the posterior distribution.\n\n\nLet us consider scenario D:\na &lt;- a4.post b &lt;- b4.post\n\n\nScenario D:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\n\n\nCS of level 0.95\nCS &lt;- qbeta(c(0.025,0.975), a, b);CS abline(v=CS,lty=“dashed”, col=“blue”) legend(0.8,8,c(“Posterior”, “Credible Set”), lty=c(1,2), col=c(“black”, “blue”), bty=“n”)\n\n\nHighest posterior density (HPD):\n\n\nLet’s start by considering a random value for h\nh &lt;- 2 curve(dbeta(x, a, b), ylab=expression(paste(pi,“(”,theta,“|x)”)), xlab=expression(theta)) abline(h=h,lty=2)\n\n\nWe need to find the values of theta such that p(theta|y) = h\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h # We decrease the density curve by h. # Now, the values we are looking for are such that translated = 0\ncurve(translated(x, a, b), add=T,lty=3,lwd=2) abline(h=0,lty=3)\nhpd1 &lt;- uniroot(translated,c(.2, .4),a,b)\\(root;hpd1\nhpd2 &lt;- uniroot(translated,c(.45, .5),a,b)\\)root;hpd2 integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)\n\n\nWe have a probability equal to 0.9152 –&gt; Decrease h\n\n\nIterative way:\nh.grid &lt;- seq(1, 2, by = 0.01)\nres &lt;- matrix(NA, ncol=4, nrow=length(h.grid)) colnames(res) &lt;- c(“HPD1”, “HPD2”, “level”, “h”)\nfor(i in 1:length(h.grid)){\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h.grid[i]\nhpd1&lt;-uniroot(translated,c(.2,.4),a,b)\\(root\n  hpd2&lt;-uniroot(translated,c(.43,.55),a,b)\\)root\nI &lt;- integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)$value\niter &lt;- i res[i,] &lt;- c(hpd1, hpd2, I, h.grid[i]) if(I &lt;= 0.95) break }\nres[1:iter,] h.grid[iter]\nHPD &lt;- res[iter-1,-c(3,4)]; HPD CS\n\n\nGraphically:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\nabline(v=CS,lty=“dashed”, col=“blue”) abline(v=HPD,lty=“dashed”, col=“red”)\nlegend(0.8,8,c(“Posterior”, “Credible Set”, “HPD”), lty=c(1,2,2), col=c(“black”, “blue”, “red”), bty=“n”)\n\n\nHPD and CS are very similar, because the posterior is\n\n\nunimodal and almost symmetrical.\n\n\nHypothesis testing:\n\n\nLet consider H0: theta &lt;= 0.3 vs H1: theta &gt; 0.3\npbeta(.3, a4, b4) pbeta(.3, a4.post, b4.post)\nODDS.prior &lt;- pbeta(.3, a4, b4)/(1-pbeta(.3, a4, b4)); ODDS.prior ODDS.post &lt;- pbeta(.3, a4.post, b4.post)/(1-pbeta(.3, a4.post, b4.post)); ODDS.post\nBayes_Factor &lt;- ODDS.post/ODDS.prior; Bayes_Factor\n\n\nData do not support H0: by adding data, our confidence on\n\n\nH0 strongly decreases\n\n\nHOMEWORK: consider a sample of size n = 10 composed of\n\n\nBernoulli trials, for which we observed s = 3 successes.\n\n\nConsider that a priori theta ~ Beta(2, 8)\n\n\n1. Which is the posterior distribution of theta?\n\n\n2. Compute the MLE and the prior and posterior means.\n\n\nAre these results reasonable?\n\n\n3. Compute and compare the CS and the HPD.\n\n\n4. Let H0 : theta in (0.3, 0.5)\n\n\nH1 : theta in (0, 0.3) U (0.5, 1)\n\n\nWhich hypothesis can you support?"
  },
  {
    "objectID": "Script4.html",
    "href": "Script4.html",
    "title": "Script 1 - Bernoulli - Beta",
    "section": "",
    "text": "You can download the R script here.\nIn this section, we will explore the Bernoulli-Beta model applied to the cardiac dataset. Specifically, we assume that \\(Y_i | \\theta \\sim Bernoulli(\\theta)\\) and that \\(\\theta \\sim Beta(a, b)\\). With these choices, we showed that the posterior distribution is \\(\\theta | \\textbf{y} \\sim Beta(a + \\sum_{i=1}^n y_i, b + n - \\sum_{i=1}^n y_i)\\).\nWe will examine four different scenarios, each corresponding to a distinct choice of hyperparameters for the Beta prior.\n\ncardiac &lt;- read.table(\"data/cardiac.csv\", header=T, sep=\";\")\nstr(cardiac)\n\n'data.frame':   100 obs. of  2 variables:\n $ Age: int  20 23 24 25 25 26 26 28 28 29 ...\n $ Chd: int  0 0 0 0 1 0 0 0 0 0 ...\n\ny &lt;- cardiac$Chd\ntable(y)\n\ny\n 0  1 \n57 43 \n\nsum(y)\n\n[1] 43\n\nlength(y)\n\n[1] 100\n\n\nThese are thw four scenarios we consider: - A: \\(\\theta \\sim Beta(1,1)\\); - B: \\(\\theta \\sim Beta(10,10)\\); - C: \\(\\theta \\sim Beta(10,5)\\); - D: \\(\\theta \\sim Beta(5,10)\\).\n\npar(mfrow=c(2,2))\ncurve(dbeta(x, 1, 1), main=\"Scenario A\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 10), main=\"Scenario B\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 10, 5), main=\"Scenario C\", xlab=expression(theta), ylab=expression(pi(theta)))\ncurve(dbeta(x, 5, 10), main=\"Scenario D\", xlab=expression(theta), ylab=expression(pi(theta)))\n\n\n\n\n\n\n\npar(mfrow=c(1,1))\n\nWe further define the L_binom function, which returns the value of the likelihood function evaluated in a specific theta point.\n\nL_Binom &lt;- function(y, theta){\n  s &lt;- sum(y)\n  n &lt;- length(y)\n  L &lt;- theta^s * (1-theta)^(n-s)\n  return(L)\n}\n\nL_Binom(y, theta=0.001)\n\n[1] 9.445671e-130\n\n\nObviously, the likelihood function does not depend on the prior distribution we impose on \\(\\theta\\). In this case, the MLE corresponds to the sample mean (blue dashed line).\n\ncurve(L_Binom(y, theta=x), main=\"Likelihood\",\n      xlab=expression(theta), lwd=2)\nabline(v=mean(y), col=\"blue\", lty=\"dashed\")\n\n\n\n\n\n\n\n\n\nScenario A:\nIn this scenario, the prior distribution coincides with a uniform distribution on the \\((0,1)\\) interval. Thus, the prior mean (red dashed line) is equal to 0.5.\n\na1 &lt;- 1; b1 &lt;- 1\n\ncurve(dbeta(x, a1, b1), main=\"Prior A\", ylim=c(0,1.4),\n      xlab=expression(theta), lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\")\n\n\n\n\n\n\n\n\nThe posterior distribution is $| Beta()\n\nn &lt;- length(y)\na1.post &lt;- a1 + sum(y)\nb1.post &lt;- b1 + n - sum(y)\n\ncurve(dbeta(x, a1.post, b1.post), main=\"Scenario A\",\n      xlab=expression(theta), lwd=2)\ncurve(dbeta(x, a1, b1), lty=\"dashed\", add=T, lwd=2)\nabline(v=a1/(a1+b1), col=\"red\", lty=\"dashed\", lwd=2)\nabline(v=mean(y), col=\"green\", lty=\"dotted\", lwd=2)\nabline(v=a1.post/(a1.post+b1.post), col=\"blue\", lty=\"dashed\", lwd=2)\nlegend(.8,8, c(\"Prior\", \"Posterior\", \"Prior Mean\", \"MLE\", \"Post. Mean\"), lwd=2,\n       col=c(\"black\", \"black\", \"red\", \"green\", \"blue\"), lty=c(2,1,2,3,2), bty=\"n\")\n\n\n\n\n\n\n\n\n\n\nThe chosen prior distribution does not favor\n\n\nany value of theta.\n\n\nThus, we selected a non-informative prior.\n\n\nThe posterior distribution is centered\n\n\naround the MLE.\n\n\nScenario B:\na2 &lt;- 10; b2 &lt;- 10\n\n\nPrior distribution:\ncurve(dbeta(x, a2, b2), main=“Prior B”, xlab=expression(theta), lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”)\n\n\nLikelihood function:\ncurve(L_Binom(y, theta=x), main=“Likelihood”, xlab=expression(theta), lwd=2) abline(v=mean(y), col=“blue”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a2.post &lt;- a2 + sum(y) b2.post &lt;- b2 + n - sum(y)\ncurve(dbeta(x, a2.post, b2.post), main=“Scenario B”, xlab=expression(theta), lwd=2) curve(dbeta(x, a2, b2), lty=“dashed”, add=T, lwd=2) abline(v=a2/(a2+b2), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a2.post/(a2.post+b2.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nNow we are still considering a symmetric prior\n\n\nwith prior mean = 0.5, but it does not\n\n\ngive same density/probability to each\n\n\nvalue/interval of theta.\n\n\nNow the posterior mean is a weighted average\n\n\nbetween prior mean and MLE.\n\n\nScenario C:\na3 &lt;- 10; b3 &lt;- 5\n\n\nPosterior distribution:\nn &lt;- length(y) a3.post &lt;- a3 + sum(y) b3.post &lt;- b3 + n - sum(y)\ncurve(dbeta(x, a3.post, b3.post), main=“Scenario C”, xlab=expression(theta), lwd=2) curve(dbeta(x, a3, b3), lty=“dashed”, add=T, lwd=2) abline(v=a3/(a3+b3), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a3.post/(a3.post+b3.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nScenario D:\na4 &lt;- 5; b4 &lt;- 10\n\n\nPosterior distribution:\nn &lt;- length(y) a4.post &lt;- a4 + sum(y) b4.post &lt;- b4 + n - sum(y)\ncurve(dbeta(x, a4.post, b4.post), main=“Scenario D”, xlab=expression(theta), lwd=2) curve(dbeta(x, a4, b4), lty=“dashed”, add=T, lwd=2) abline(v=a4/(a4+b4), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a4.post/(a4.post+b4.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,8, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\n\n\nWe may summarize the (prior and) posterior distribution\n\n\nby some measures:\nBeta.Exp &lt;- function(a, b) a/(a+b) Beta.Var &lt;- function(a, b)(ab)/((a+b)^2(a+b+1)) Beta.Mode &lt;- function(a, b){ ifelse(a&gt;1 & b&gt;1, (a-1)/(a+b-2), NA) } Beta.Median &lt;- function(a, b) qbeta(.5, a, b)\nmeasures &lt;- matrix(NA, ncol=6, nrow=4) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post) for(i in 1:4){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nIn this simple scenario, even considering\n\n\ndifferent priors, we do not have posteriors\n\n\nleading to very different point estimates.\n\n\nThis is because the empirical evidence\n\n\n(i.e., our data) is much\n\n\nstronger than our prior belief.\n\n\nLet us consider an additional scenario where\n\n\nwe strongly believe that most people\n\n\ndo not have cardiovascular disease.\na5 &lt;- 100 b5 &lt;- 1000\n\n\nPrior distribution:\ncurve(dbeta(x, a5, b5), main=“Prior E”, xlab=expression(theta)) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”)\n\n\nPosterior distribution:\nn &lt;- length(y) a5.post &lt;- a5 + sum(y) b5.post &lt;- b5 + n - sum(y)\ncurve(dbeta(x, a5.post, b5.post), main=“Scenario E”, xlab=expression(theta), lwd=2) curve(dbeta(x, a5, b5), lty=“dashed”, add=T, lwd=2) abline(v=a5/(a5+b5), col=“red”, lty=“dashed”, lwd=2) abline(v=mean(y), col=“green”, lty=“dotted”, lwd=2) abline(v=a5.post/(a5.post+b5.post), col=“blue”, lty=“dashed”, lwd=2) legend(.8,40, c(“Prior”, “Posterior”, “Prior Mean”, “MLE”, “Post. Mean”), lwd=2, col=c(“black”, “black”, “red”, “green”, “blue”), lty=c(2,1,2,3,2), bty=“n”)\nmeasures &lt;- matrix(NA, ncol=6, nrow=5) rownames(measures) &lt;- c(“A”, “B”, “C”, “D”, “E”) colnames(measures) &lt;- c(“a.post”, “b.post”, “Exp”, “Mode”, “Median”, “Var”)\nmeasures[,1] &lt;- c(a1.post,a2.post,a3.post,a4.post,a5.post) measures[,2] &lt;- c(b1.post,b2.post,b3.post,b4.post,b5.post) for(i in 1:5){ a &lt;- measures[i,1] b &lt;- measures[i,2] measures[i,3] &lt;- Beta.Exp(a, b) measures[i,4] &lt;- Beta.Mode(a, b) measures[i,5] &lt;- Beta.Median(a, b) measures[i,6] &lt;- Beta.Var(a, b) }\nround(measures,4)\n\n\nInterval Estimates:\n\n\nCredible Sets (CS).\n\n\nThe CS are very easy to compute. Indeed, we only have to compute\n\n\nquantiles of the posterior distribution.\n\n\nLet us consider scenario D:\na &lt;- a4.post b &lt;- b4.post\n\n\nScenario D:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\n\n\nCS of level 0.95\nCS &lt;- qbeta(c(0.025,0.975), a, b);CS abline(v=CS,lty=“dashed”, col=“blue”) legend(0.8,8,c(“Posterior”, “Credible Set”), lty=c(1,2), col=c(“black”, “blue”), bty=“n”)\n\n\nHighest posterior density (HPD):\n\n\nLet’s start by considering a random value for h\nh &lt;- 2 curve(dbeta(x, a, b), ylab=expression(paste(pi,“(”,theta,“|x)”)), xlab=expression(theta)) abline(h=h,lty=2)\n\n\nWe need to find the values of theta such that p(theta|y) = h\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h # We decrease the density curve by h. # Now, the values we are looking for are such that translated = 0\ncurve(translated(x, a, b), add=T,lty=3,lwd=2) abline(h=0,lty=3)\nhpd1 &lt;- uniroot(translated,c(.2, .4),a,b)\\(root;hpd1\nhpd2 &lt;- uniroot(translated,c(.45, .5),a,b)\\)root;hpd2 integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)\n\n\nWe have a probability equal to 0.9152 –&gt; Decrease h\n\n\nIterative way:\nh.grid &lt;- seq(1, 2, by = 0.01)\nres &lt;- matrix(NA, ncol=4, nrow=length(h.grid)) colnames(res) &lt;- c(“HPD1”, “HPD2”, “level”, “h”)\nfor(i in 1:length(h.grid)){\ntranslated &lt;- function(x, a, b) dbeta(x,a, b)-h.grid[i]\nhpd1&lt;-uniroot(translated,c(.2,.4),a,b)\\(root\n  hpd2&lt;-uniroot(translated,c(.43,.55),a,b)\\)root\nI &lt;- integrate(dbeta, lower=hpd1, upper=hpd2, shape1=a, shape2=b)$value\niter &lt;- i res[i,] &lt;- c(hpd1, hpd2, I, h.grid[i]) if(I &lt;= 0.95) break }\nres[1:iter,] h.grid[iter]\nHPD &lt;- res[iter-1,-c(3,4)]; HPD CS\n\n\nGraphically:\ncurve(dbeta(x, a, b), main=“Scenario D”, xlab=expression(theta), lwd=2)\nabline(v=CS,lty=“dashed”, col=“blue”) abline(v=HPD,lty=“dashed”, col=“red”)\nlegend(0.8,8,c(“Posterior”, “Credible Set”, “HPD”), lty=c(1,2,2), col=c(“black”, “blue”, “red”), bty=“n”)\n\n\nHPD and CS are very similar, because the posterior is\n\n\nunimodal and almost symmetrical.\n\n\nHypothesis testing:\n\n\nLet consider H0: theta &lt;= 0.3 vs H1: theta &gt; 0.3\npbeta(.3, a4, b4) pbeta(.3, a4.post, b4.post)\nODDS.prior &lt;- pbeta(.3, a4, b4)/(1-pbeta(.3, a4, b4)); ODDS.prior ODDS.post &lt;- pbeta(.3, a4.post, b4.post)/(1-pbeta(.3, a4.post, b4.post)); ODDS.post\nBayes_Factor &lt;- ODDS.post/ODDS.prior; Bayes_Factor\n\n\nData do not support H0: by adding data, our confidence on\n\n\nH0 strongly decreases\n\n\nHOMEWORK: consider a sample of size n = 10 composed of\n\n\nBernoulli trials, for which we observed s = 3 successes.\n\n\nConsider that a priori theta ~ Beta(2, 8)\n\n\n1. Which is the posterior distribution of theta?\n\n\n2. Compute the MLE and the prior and posterior means.\n\n\nAre these results reasonable?\n\n\n3. Compute and compare the CS and the HPD.\n\n\n4. Let H0 : theta in (0.3, 0.5)\n\n\nH1 : theta in (0, 0.3) U (0.5, 1)\n\n\nWhich hypothesis can you support?"
  }
]