[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Inference II",
    "section": "",
    "text": "Statistical Inference II provides an introduction to Bayesian data analysis, covering prior and posterior distributions, classical one-parameter models, prior elicitation, posterior-based inference, MCMC methods, and Bayesian approaches to linear and generalized linear models."
  },
  {
    "objectID": "index.html#syllabus",
    "href": "index.html#syllabus",
    "title": "Statistical Inference II",
    "section": "Syllabus",
    "text": "Syllabus\n\nIntroduction to Bayesian data analysis: prior and posterior distributions for inference.\nOne-parameter models: Binomial-Beta, Poisson-Gamma, Exponential-Gamma, and Normal-Normal.\nMethods for prior elicitation.\nInference based on the posterior distribution (point and interval estimates; hypotheses testing).\nSimulation-based inference: MCMC methods.\nLinear and generalized linear models from a Bayesian perspective."
  },
  {
    "objectID": "index.html#libri-di-testo",
    "href": "index.html#libri-di-testo",
    "title": "Statistical Inference II",
    "section": "Libri di testo",
    "text": "Libri di testo\n\nAlbert, J. & M. Rizzo (2012). R by Example. Springer.\nM. Grigoletto, F. Pauli, L. Ventura, Modello lineare, teoria e applicazioni con R. Giappichelli, 2017\nJ. Fox. Applied regression analysis and generalized linear models, third edition. Sage.\nD. Piccolo, Statistica, Terza edizione, Il Mulino."
  },
  {
    "objectID": "Code1.html",
    "href": "Code1.html",
    "title": "Script 1 -",
    "section": "",
    "text": "Soluzione\nmu &lt;- 1\nsigma2 &lt;- 2\nx &lt;- -1\n\nf_x &lt;- (2*pi*sigma2)^(-1/2)*exp(-1/(2*sigma2)*(x-mu)^2); f_x"
  },
  {
    "objectID": "Esercizi.html",
    "href": "Esercizi.html",
    "title": "Esercizi R",
    "section": "",
    "text": "Il modo migliore (e forse l’unico) per padroneggiare un linguaggio di programmazione è quello di continuare ad esercitarsi. Si consiglia vivamente di non guardare le soluzioni prima di aver provato a ragionare e sbattere la testa in autonomia sulla risoluzione degli esercizi.\nCome sempre, non esiste un unico modo per ottenere lo stesso risultato: approcci differenti dalle soluzioni proposte possono comunque portare al risultato corretto!"
  },
  {
    "objectID": "Esercizi.html#parte-1-introduzione-ad-r",
    "href": "Esercizi.html#parte-1-introduzione-ad-r",
    "title": "Esercizi R",
    "section": "Parte 1: Introduzione ad R",
    "text": "Parte 1: Introduzione ad R\n\nEsercizio 1.1\nSi consideri \\(X \\sim N(\\mu, \\sigma^2)\\).\n\nSi calcoli il valore della funzione di densità di \\(X\\), \\(f(x)\\), in corrispondenza del punto \\(x=-1\\) considerando \\(\\mu = 1\\) e \\(\\sigma^2 = 2\\).\n\n\n\nSoluzione\nmu &lt;- 1\nsigma2 &lt;- 2\nx &lt;- -1\n\nf_x &lt;- (2*pi*sigma2)^(-1/2)*exp(-1/(2*sigma2)*(x-mu)^2); f_x\n\n\n\nMantenendo gli stessi valori per \\(\\mu\\) e \\(\\sigma^2\\), si rappresenti graficamente la densità di \\(X\\) nel range \\((-5, 5)\\).\n\n\n\nSoluzione\ncurve((2*pi*sigma2)^(-1/2)*exp(-1/(2*sigma2)*(x-mu)^2), xlim=c(-5,5),\n      ylab = \"f(x)\", xlab=\"x\")\n\n\n\nSi sovraimponga al grafico precedente una linea verticale in corrispondenza del punto \\(-1\\) ed una linea orizzontale in corrispondenza del punto \\(f(-1)\\).\n\n\n\nSoluzione\ncurve((2*pi*sigma2)^(-1/2)*exp(-1/(2*sigma2)*(x-mu)^2), xlim=c(-5,5),\n      ylab = \"f(x)\", xlab=\"x\")\nabline(h=f_x, v=-1, col=\"red\", lty=\"dashed\")\n\n\n\n\nEsercizio 1.2\n\nSi sfrutti la funzione sum() per calcolare la somma dei primi \\(n = 600\\) numeri interi.\n\n\n\nSoluzione\nn &lt;- 600\nx &lt;- 1:n\n\nsum(x)\n\n\n\nSi può dimostrare che la somma dei primi \\(n\\) numeri interi è pari a \\(\\displaystyle \\sum_{i=1}^n i = \\frac{n(n+1)}{2}\\). Si utilizzi questo risultato per verificare la correttezza di quanto fatto al punto 1.\n\n\n\nSoluzione\nn &lt;- 600\nn*(n+1)/2\n\n\n\n\nEsercizio 1.3\nSi crei un vettore v contenente i numeri interi da 1 a 250.\n\nSi estraggano gli elementi in posizione pari e si calcoli la loro somma.\n\n\n\nSoluzione\nv &lt;- 1:250\nsum(v[2*(1:floor(length(v)/2))])\n\n\n\nSi utilizzi il vettore v per determinare il numero di interi tra 1 e 250 che risultano maggiori di 97 e dispari.\n\n\n\nSoluzione\nv &lt;- 1:250\nbooleani &lt;- v &gt; 97 & (v%%2 == 1);booleani\nsum(booleani)\n\n\n\n\nEsercizio 1.4\n\nSi scriva una funzione che, senza utilizzare la funzione t(), restituisca la trasposta di una matrice mat ricevuta come argomento.\n\n\n\nSoluzione\nA &lt;- matrix(c(1,3,4,2,9,0), ncol=2)\n\nmy_trasp &lt;- function(mat){\n  ncol_mat &lt;- ncol(mat)\n  nrow_mat &lt;- nrow(mat)\n  \n  trasp &lt;- matrix(NA, ncol=nrow_mat, nrow=ncol_mat)\n  \n  for(r in 1:nrow_mat){\n    trasp[,r] &lt;- mat[r,]\n  }\n  return(trasp)\n}\n\n\n\nSi costruisca una matrice a piacere con cui verificare che il codice prodotto produca lo stesso risultato della funzione t().\n\n\n\nSoluzione\nA &lt;- matrix(c(1,3,4,2,9,0), ncol=2)\n\nA\nmy_trasp(A)\nt(A)\n\n\n\n\nEsercizio 1.5\nSi scriva una funzione che permetta di calcolare il prodotto scalare tra due vettori di stessa lunghezza. Qualora i due vettori dati in input non dovessero avere la stessa lunghezza, la funzione deve portare ad un messaggio di errore.\n\n\nSoluzione\nprod_scal &lt;- function(a,b){\n  if(length(a) != length(b)){\n    print(\"Errore: i due vettori devono avere la stessa dimensione\")\n  } else {\n    somma &lt;- 0\n    for(i in 1:length(a)){\n      somma &lt;- somma + (a[i]*b[i])\n    }\n    return(somma)\n  }\n}\n\na &lt;- c(10, 2, 7)\nb &lt;- 4:6\nc &lt;- c(1, 1, 1, 1)\n\nprod_scal(a, b)\nprod_scal(a, c)\n\n\n\n\nEsercizio 1.6\nSi scriva una funzione che riceva come argomento un numero intero e restituisca TRUE se il numero è primo e FALSE altrimenti.\n\n\nSoluzione\nis.primo &lt;- function(x){\n  divisori &lt;- 2:(x-1)\n  if(any(x%%divisori == 0)) {\n    return(FALSE)\n  } else {\n    return(TRUE)\n  }\n  \n}\n\nis.primo(9)\nis.primo(13)\n\n\n\n\nEsercizio 1.7\n\nSi scriva una funzione che riceva come argomenti un vettore voti ed un vettore CFU. La funzione deve restituire una lista, avente come primo elemento la media aritmetica dei voti e come secondo elemento la media aritmetica ponderata degli stessi.\n\n\n\nSoluzione\nmedie &lt;- function(voti, CFU){\n  output &lt;- list()\n  output$media &lt;- sum(voti)/length(voti)\n  output$media_ponderata &lt;- sum(voti*CFU)/sum(CFU)\n  \n  return(output)\n}\n\n\n\nSi utilizzi la funzione appena scritta per calcolare le medie dei propri voti, verificando la correttezza dei risultati tramite il proprio libretto online.\n\n\n\nSoluzione\n# Esempio 1:\nmiei_voti &lt;- rep(18, 7)\nmiei_CFU &lt;- c(6, 9, 9, 6, 9, 6, 6)\nmedie(miei_voti, miei_CFU)\n\n# Esempio 2:\nmiei_voti2 &lt;- c(27, 30, 18, 25, 30, 23, 30)\nmiei_CFU2 &lt;- c(6, 9, 9, 6, 9, 6, 6)\nmedie(miei_voti2, miei_CFU2)\n\n\n\n\nEsercizio 1.8\nSi consideri un vettore numerico a piacere.\n\nSi scriva una funzione che restituisca il vettore standardizzato.\n\n\n\nSoluzione\nx &lt;- seq(5, 271.2, by=.86)\n\nstand &lt;- function(v) {\n  s &lt;- (v-mean(v))/sd(v)\n  return(s)\n}\ns &lt;- stand(x)\nc(mean(s), sd(s))\n\n\n\nSi scriva una funzione che normalizzi il vettore (cioè che scali il vettore in modo tale che i suoi elementi assumano valori in \\([0,1]\\)).\n\n\n\nSoluzione\nx &lt;- seq(5, 271.2, by=.86)\n\nnorm &lt;- function(v) {\n  n &lt;- (v-min(v))/(max(v)-min(v))\n  return(n)\n}\nn &lt;- norm(x)\nc(min(n), max(n))\n\n\n\n\nEsercizio 1.9\nSi implementi una funzione che riceva due interi \\(n\\) e \\(k\\) e restituisca una tavola pitagorica di dimensione \\(n \\times k\\).\n\n\nSoluzione\npitag &lt;- function(n, k){\n  out &lt;- matrix(NA, nrow=n, ncol=k)\n  \n  for(i in 1:n){\n    for(j in 1:k){\n      out[i,j] &lt;- i*j\n    }\n  }\n  return(out)\n}\n\npitag(5,4)\n\n\n\n\nEsercizio 1.10\nIl seguente esercizio è estratto da un tema d’esame del prof. Rigon.\nI numeri di Stirling del secondo tipo \\(S(n,k)\\) rappresentano il numero di possibili partizioni di \\(n\\) oggetti formate da \\(k\\) elementi. Si può dimostrare che \\[\\displaystyle S(n,k) = \\frac{1}{k!} \\sum_{j=0}^k (-1)^{k-j} {k \\choose j} j^n,\\] per \\(k = 1, \\dots, n\\). Invece, il numero di Bell \\(B(n)\\) rappresenta il numero di possibili partizioni di un insieme di \\(n\\) elementi, indipendentemente dal numero di termini: \\[\\displaystyle B(n) = \\sum_{k=1}^n S(n,k).\\]\n\nSi scrivano le funzioni my_stirling(n,k) e my_bell(n) che calcolano, rispettivamente, \\(S(n,k)\\) e \\(B(n)\\).\n\n\n\nSoluzione\nmy_stirling &lt;- function(n,k){\n  j &lt;- 0:k\n  sum((-1)^(k-j)*choose(k,j)*j^n)/(factorial(k))\n}\n\nmy_bell &lt;- function(n){\n  stirling &lt;- numeric(n)\n  for(k in 1:n){\n    stirling[k] &lt;- my_stirling(n,k)\n  }\n  return(sum(stirling))\n}\n\n\n\nIn quanti modi è possibile dividere un insieme di 10 oggetti utilizzando gruppi di 5 elementi?\n\n\n\nSoluzione\nmy_stirling(10,5)\n\n\n\nIn quanti modi è possibile partizionare un insieme di 10 elementi?\n\n\n\nSoluzione\nmy_bell(10)\n\n\n\n\nEsercizio 1.11\nSi considerino le matrici \\(A\\) e \\(B\\) definite nel seguente modo: \\[A = \\begin{bmatrix}\n   2 & 1 & 5 & 3\\\\\n   6 & 7 & 9 & 1\\\\\n   8 & 3 & 0 & 0\n   \\end{bmatrix} \\text{ e } B = \\begin{bmatrix}\n   -2 & 4 & 7 \\\\\n   -6 & 3 & 5 \\\\\n   3 & 3 & -8 \\\\\n   4 & 4 & -2\n   \\end{bmatrix}\\]\n\nSi definiscano tali matrici in R.\n\n\n\nSoluzione\nA &lt;- matrix(c(2, 1, 5, 3, 6, 7, 9, 1, 8, 3, 0, 0), byrow = T, ncol = 4)\n\nB &lt;- matrix(c(-2, 4, 7,-6, 3, 5, 3, 3, -8, 4, 4, -2), byrow = T, ncol = 3)\n\n\n\nSi aggiunga alla matrice \\(A\\) un’ulteriore riga pari all’ultima colonna della matrice \\(B\\).\n\n\n\nSoluzione\nA &lt;- rbind(A, B[,3])\nA\n\n\n\nSi consideri e si risolva il seguente sistema lineare:\n\n\\[A =  \\left\\{\\begin{array}{l}\n   2x + y + 5z + 3w = -3\\\\\n   6x + 7y + 9z + w = 1\\\\\n   8x + 3y = 0  \\\\\n   7x + 5y  -8z -2w = -10\n   \\end{array}\\right.\\]\n\n\nSoluzione\nc &lt;- c(-3, 1, 0, -10)\n\nsoluzione &lt;- solve(A) %*% c; soluzione\n\n\n\nSi verifichi che la soluzione individuata sia effettivamente una soluzione del sistema proposto.\n\n\n\nSoluzione\nsol &lt;- as.numeric(soluzione)\n\nall(c(round(sum(A[1,] * sol),10) == c[1],\n      round(sum(A[2,] * sol),10) == c[2],\n      round(sum(A[3,] * sol),10) == c[3],\n      round(sum(A[4,] * sol),10) == c[4]))"
  },
  {
    "objectID": "Esercizi.html#parte-2-descrittiva",
    "href": "Esercizi.html#parte-2-descrittiva",
    "title": "Esercizi R",
    "section": "Parte 2: Descrittiva",
    "text": "Parte 2: Descrittiva\n\nEsercizio 2.1\nSi considerino i dati presenti nel dataset Prestige del pacchetto carData, riguardanti un certo insieme di professioni. I dati sono stati raccolti nel 1971 in Canada.\n\nQuante professioni sono state analizzate? Quante variabili sono state raccolte?\n\n\n\nSoluzione\nlibrary(carData)\ndata(Prestige)\n\ndim(Prestige)\nnrow(Prestige)\nncol(Prestige)\n\n\n\nSi utilizzi la funzione help() per comprendere quali variabili sono state raccolte.\n\n\n\nSoluzione\nhelp(Prestige)\n\n\n\nSono presenti dei valori mancanti nel dataset? Se si, si crei un data.frame che esclude tutte le unità statistiche con almeno un mancante.\n\n\n\nSoluzione\nanyNA(Prestige)\n\nis.na(Prestige)\n\nquali_con_missing &lt;- rowSums(is.na(Prestige)) &gt; 0\nsum(quali_con_missing) # 4 unità da eliminare\nPrestige2 &lt;- subset(Prestige, !quali_con_missing)\n\n# Oppure:\nquali_complete &lt;- complete.cases(Prestige)\nPrestige2 &lt;- subset(Prestige, quali_complete)\n\n\n\nSi rappresenti graficamente la distribuzione delle variabile women. Si commenti questo grafico in relazione alle pari opportunità nel mondo del lavoro.\n\n\n\nSoluzione\nhist(Prestige2$women, prob = T, main = \"Istogramma variabile women\")\n\n\n\nSi ottenga la funzione di ripartizione empirica della variabile women. La si rappresenti graficamente e si ottenga il suo valore in corrispondenza di 50. Cosa ci dice questo valore, in merito alla disparità di genere?\n\n\n\nSoluzione\necdf_women &lt;- ecdf(Prestige2$women)\n\necdf_women(50)\n\nplot(ecdf_women)\n\n\n\nSi rappresenti graficamente la relazione congiunta di women ed income. Che relazione sembra esserci tra queste due variabili?\n\n\n\nSoluzione\nplot(Prestige2$women, Prestige2$income, pch = 20)\n\n\n\nSi colorino i punti del grafico precedente in modo tale che si possa tenere conto della tipologia del lavoro. Che informazioni si possono trarre?\n\n\n\nSoluzione\nplot(Prestige2$women, Prestige2$income, pch = 20, col = Prestige2$type)\nlevels(Prestige2$type) # neri = Colletti blu; rossi = Professionisti, manager e tecnici; verdi = colletti bianchi\n\n\n\nSi aggiunga al dataset una variabile women2. Questa variabile deve essere un factor avente tre livelli: “unbalanced_men” se women risulta minore o uguale a 40, “unbalance_women” se women è maggiore di 60 e “balanced” altrimenti. Si ottengano le frequenze assolute e relative di women2.\n\n\n\nSoluzione\nPrestige2$women2 &lt;- factor(ifelse(Prestige2$women &lt;= 40, \"unbalanced_man\",\n                        ifelse(Prestige2$women &gt; 60, \"unbalanced_women\", \"balanced\")))\n\ntable(Prestige2$women2)\ntable(Prestige2$women2)/nrow(Prestige2)\n\n\n\n\nEsercizio 2.2\nSi carichino in R i dati contenuti nel file Pokemon.csv, scaricabili al seguente link. Il dataset contiene dati relativi a 800 Pokémon e le seguetni variabili:\n\nID: un numero identificativo del Pokémon;\nName: il nome del Pokémon;\nType1 e Type2: il tipo primario e quello secondario del Pokémon;\nTotal: la somma delle statistiche del Pokémon;\nHP: i Punti Vita (Health Points) del Pokémon;\nAttack e SpAtk: le statistiche attacco e attacco speciale del Pokémon;\nDefense e sPDef: le statistiche difesa e difesa speciale del Pokémon;\nSpeed: la statistica velocità del Pokémon;\nGeneration: la [generazione](https://it.wikipedia.org/wiki/Pok%C3%A9mon_(serie_di_videogiochi) del Pokémon;\nLegendary: stringa facente riferimento al fatto che il Pokémon sia leggendario (True) o no (False).\n\n\n\nSoluzione\npkmn &lt;- read.table(\"Pokemon.csv\", header = TRUE, sep = \",\", \n                   stringsAsFactors = FALSE)\n\n\n\nSi ispezioni la variabile Legendary. Come mai non è di classe logical, pur avendo modalità associabili a “Vero” e “Falso”? Si sovrascriva la variabile con una sua versione logical.\n\n\n\nSoluzione\nstr(pkmn$Legendary)\ntable(pkmn$Legendary)\n\npkmn$Legendary &lt;- pkmn$Legendary == \"True\"\n\nstr(pkmn$Legendary)\ntable(pkmn$Legendary)\n\n\n\nSi eliminino dal dataset tutti i Pokémon che contengono nel loro nome la stringa “Mega”, ad eccezione del Pokémon chiamato “Meganium”. Per tale scopo, si utilizzi la funzione grep() (dall’help: grep(value = FALSE) returns a vector of the indices of the elements of x that yielded a match).\n\n\n\nSoluzione\nrighe_mega &lt;- grep(\"Mega\", pkmn$Name); righe_mega\n\nwhich(pkmn$Name == \"Meganium\")\n\n# Devo quindi eliminare tutte le righe indicate da righe_mega ad eccezione della 169\n\nwhich(righe_mega == 169)\nrighe_mega2 &lt;- righe_mega[-16]\n\n# Altro modo: mi accorgo che tutti i nomi con Mega, ad eccezione di Meganium,\n# hanno uno spazio (blank) dopo la parola Mega:\npkmn$Name[righe_mega]\nrighe_mega2 &lt;- grep(\"Mega \", pkmn$Name); righe_mega2\n\npkmn &lt;- pkmn[-righe_mega,]\n\n\n\nSi crei un dataset pkmn_sub contenente i dati dei Pokémon appartenenti alla prima o alla seconda generazione. D’ora in poi, si faccia riferimento a questo data.frame.\n\n\n\nSoluzione\npkmn_sub &lt;- subset(pkmn, Generation == 1 | Generation == 2)\n\n\n\nQuali variabili dovrebbero essere factor? Le si converta.\n\n\n\nSoluzione\npkmn_sub$Type1 &lt;- as.factor(pkmn_sub$Type1)\npkmn_sub$Type2 &lt;- as.factor(pkmn_sub$Type2)\npkmn_sub$Generation &lt;- as.factor(pkmn_sub$Generation)\n\n\n\nCome si distribuiscono i Pokémon leggendari tra le due generazioni considerate? Si misuri il grado di connessione con un opportuno indice normalizzato.\n\n\n\nSoluzione\ntt &lt;- table(pkmn_sub$Generation, pkmn_sub$Legendary); tt\nplot(tt)\n\nmarginali_gen &lt;- as.numeric(table(pkmn_sub$Generation))\nmarginali_leg &lt;- as.numeric(table(pkmn_sub$Legendary))\n\nn_gen &lt;- length(marginali_gen)\nn_leg &lt;- length(marginali_leg)\nn &lt;- nrow(pkmn_sub)\n\nfreq_attese &lt;- matrix(NA, nrow = n_gen, ncol = n_leg)\n\nchi2 &lt;- 0\n\nfor(i in 1:n_gen){\n  for(j in 1:n_leg){\n    freq_attese[i,j] &lt;- marginali_gen[i]*marginali_leg[j]/n\n    \n    chi2 &lt;- chi2 + (((tt[i,j] - freq_attese[i,j])^2)/(freq_attese[i,j]))\n  }\n}\nchi2\n\nchi2_max &lt;- n*min(n_gen-1, n_leg - 1)\nchi2_Norm &lt;- chi2/chi2_max; chi2_Norm\n\n\n\nSi calcoli, tramite la sua definizione, il valore della covarianza tra Attack e Defense. Si confronti il risultato ottenuto con quello fornito dalla funzione cov().\n\n\n\nSoluzione\nmy_cov &lt;- \n  mean((pkmn_sub$Attack - mean(pkmn_sub$Attack))*(pkmn_sub$Defense - mean(pkmn_sub$Defense)))\n\ncov(pkmn_sub$Attack, pkmn_sub$Defense)\ncov(pkmn_sub$Attack, pkmn_sub$Defense)*(n-1)/n\n\n\n\nSi ottengano i boxplot relativi alla distribuzione di Attack condizionata per Type1.\n\n\n\nSoluzione\nboxplot(pkmn_sub$Attack ~ pkmn_sub$Type1, xlab = \"Tipo1\", ylab = \"Attacco\")\n\n\n\nSi proponga un metodo per ottenere le medie condizionate di Attack entro ogni modalità di Type1.\n\n\n\nSoluzione\nquanti_tipi &lt;- length(unique(pkmn_sub$Type1))\nmedie_condiz &lt;- numeric(quanti_tipi)\nnames(medie_condiz) &lt;- levels(pkmn_sub$Type1)\n\nmodalita_type &lt;- levels(pkmn_sub$Type1)\n\nfor(i in 1:quanti_tipi){\n  data_temp &lt;- subset(pkmn_sub, Type1 == modalita_type[i])\n  \n  medie_condiz[i] &lt;- mean(data_temp$Attack)\n}\n\n# Oppure:\nhelp(aggregate)\nmedie_condiz_2 &lt;- aggregate(Attack ~ Type1, data = pkmn_sub, FUN = mean, na.rm = TRUE)\n\nmedie_condiz\nmedie_condiz_2\n\n\n\nSi costruisca un data.frame contenente esclusivamente le variabili quantitative di pkmn_sub. Si utilizzi questo data.frame per costruire la matrice di correlazione (arrotondata alla terza cifra decimale) e la matrice di diagrammi a dispersione. Si colorino i punti dei diagrammi a dispersione sulla base del valore di Legendary.\n\n\n\nSoluzione\npkmn_quantit &lt;- subset(pkmn_sub, select = Total:Speed)\n# pkmn_quantit &lt;- subset(pkmn_sub, select = c(Total, HP, Attack, Defense, SpAtk, SpDef, Speed))\n\nround(cor(pkmn_quantit), 3)\nplot(pkmn_quantit, pch = 20, col = as.factor(pkmn_sub$Legendary))\n\n\n\n\nEsercizio 2.3\nSi consideri il dataset flights del pacchetto nycflights13, relativo a voli aerei partiti da aeroporti di New York nel 2013. Una volta caricato il dataset, si legga la relativa pagina di help per comprendere le variabili presenti.\nL’oggetto flights è di classe tibble, una classe proposta negli ultimi anni per gestire dataset in modo differente rispetto ai classici data.frame. Possiamo definire i tibble come una sottoclasse dei data.frame (quindi tutti i tibble sono data.frame, ma non tutti i data.frame sono tibble). Si faccia riferimento a questo link per maggiori informazioni.\n\n\nSoluzione\nlibrary(nycflights13)\ndata(\"flights\")\nclass(flights)\n\nhelp(\"flights\")\n\n\n\nSi sovrascriva l’oggetto flights, forzando la sua classe ad essere data.frame. (N.B.: in generale non è obbligatorio convertire la classe di un tibble per lavorare con esso.)\n\n\n\nSoluzione\nflights &lt;- as.data.frame(flights)\n\n\n\nQuale dei tre aeroporti di New York è quello da cui sono partiti più voli nel 2013?\n\n\n\nSoluzione\ntt &lt;- table(flights$origin); tt\n\nnames(tt)[which.max(tt)]\n\n\n\nSi vuole indagare l’eterogeneità della variabile month, per valutare se le partenze possono ritenersi equiripartite nei mesi dell’anno. Si calcolino quindi l’indice di Gini normalizzato e l’indice di Shannon normalizzato.\n\n\n\nSoluzione\ntt_month &lt;- table(flights$month)\nf &lt;- tt_month/sum(tt_month)\nk &lt;- length(f)\nG &lt;- sum(f*(1-f))\nG_N &lt;- G*k/(k-1); G_N\n\nH &lt;- -sum(f*log(f))\nH_N &lt;- H/log(k); H_N\n\n\n\nSi aggiunga al dataset una variabile factor chiamata arrival e che assuma modalità “hearly”, “on time” e “delay” sulla base del fatto che l’aereo sia arrivato in anticipo, puntuale o in ritardo.\n\n\n\nSoluzione\nflights$arrival &lt;- \n  factor(ifelse(flights$arr_delay &lt; 0, \"early\",\n            ifelse(flights$arr_delay &gt; 0, \"delay\", \n                   \"on time\")))\ntable(flights$arrival)\n\n\n\nSi aggiunga al dataset una nuova variabile total_delay, data dalla somma del ritardo alla partenza e ritardo all’arrivo.\n\n\n\nSoluzione\nflights$total_delay &lt;- flights$dep_delay + flights$arr_delay\n\n\n\nSi calcoli il ritardo totale medio per compagnia aerea (in inglese carrier). Quale compagnia sembra essere la più efficiente, sulla base di questa semplice analisi?\n\n\n\nSoluzione\nmedia_ritardi &lt;- aggregate(total_delay ~ carrier, data = flights, FUN = mean, na.rm = TRUE)\n\n# altrimenti possiamo procedere filtrando:\n\nmedia_ritardi_2 &lt;- numeric(length(unique(flights$carrier)))\nnames(media_ritardi_2) &lt;- unique(flights$carrier)\n\nfor(i in 1:length(unique(flights$carrier))){\n  sub &lt;- \n    subset(flights, carrier == unique(flights$carrier)[i])\n  \n  media_ritardi_2[i] &lt;- mean(sub$total_delay, na.rm = T)\n}\n\nmedia_ritardi\nmedia_ritardi_2\n\nwhich.min(media_ritardi_2)\n\n\n\nSi proponga un metodo per costruire la variabile route (tratta). Si determini quante sono le tratte osservate e quale, tra queste, è la più frequentata.\n\n\n\nSoluzione\nflights$route &lt;- paste(flights$origin, \" - \", flights$dest, sep=\"\")\n\nlength(unique(flights$route))\n\ntt_route &lt;- table(flights$route)\nnames(tt_route)[which.max(tt_route)]\n\n\n\nIn future analisi legate al turismo, si vorrà studiare i soli voli decollati nel periodo estivo. A tal fine, si costruisca un dataset flights_summer riguardanti i voli partiti tra il 1 giugno ed il 31 agosto.\n\n\n\nSoluzione\nflights_summer &lt;- subset(flights, month %in% c(6,7,8))\n\n\n\n\nEsercizio 2.4\nSi consideri il dataset olympics.RData (scaricabile al seguente link), contenente dati relativi alle Olimpiadi di Londra 2012. In particolare, il dataset contiente le seguenti variabili:\n\nCountry: nome del paese;\nGoldMedals: numero di medaglie d’oro vinte a Londra 2012;\nSilver: numero di medaglie d’argento vinte a Londra 2012;\nBronze: numero di medaglie di bronzo vinte a Londra 2012;\nTotalMedals: numero totale di medaglie vinte a Londra 2012;\nIncome: reddito pro capite (in 10,000$);\nPopnSize: popolazione del paese (in miliardi);\nGDP: gross domestic product (PIL).\n\n\nSi carichi in memoria il dataset.\n\n\n\nSoluzione\nload(\"olympics.RData\")\n\n\n\nSi modifichi il nome della variabile GoldMedals in Gold.\n\n\n\nSoluzione\ncolnames(Olympics)[2] &lt;- \"Gold\"\n\n\n\nSi modifichi il data.frame in modo tale che il nome delle righe corrisponda al nome del paese. Rimuovere quindi eventuali variabili divenute ormai ridondanti.\n\n\n\nSoluzione\nrownames(Olympics) &lt;- Olympics$Country\nOlympics &lt;- subset(Olympics, select=-Country)\n\n\n\nQual è il paese che ha vinto il minor numero di medaglie d’oro? E quello che ha vinto complessivamente meno medaglie?\n\n\n\nSoluzione\nOlympics[which.min(Olympics$Gold),]\nOlympics[which.min(Olympics$TotalMedals),]\n\n\n\nSi definisca una finestra grafica che possa contenere quattro grafici, distribuiti su due righe e due colonne. Il grafico in alto a sinistra deve contenere una opportuna rappresentazione grafica della variabile TotalMedals, mentre i restanti tre devono essere diagrammi a dispersione tra la variabile TotalMedals e Income, PopnSize e GDP.\n\n\n\nSoluzione\npar(mfrow=c(2,2))\nplot(table(Olympics$TotalMedals), ylab = \"Freq.\", xlab = \"Medaglie totali\")\nplot(Olympics$TotalMedals ~ Olympics$Income, pch=20, ylab=\"Medaglie totali\", xlab=\"Reddito\")\nplot(Olympics$TotalMedals ~ Olympics$PopnSize, pch=20, ylab=\"Medaglie totali\", xlab=\"Popolazione\")\nplot(Olympics$TotalMedals ~ Olympics$GDP, pch=20, ylab=\"Medaglie totali\", xlab=\"PIL\")\npar(mfrow=c(1,1))\n\n\n\nCreare un data.frame denominato medals_composition che faccia riferimenti ai soli paesi che hanno conquistato almeno una medaglia e che contenga la composizione delle medaglie vinte da ciascun paese, specificata in base alle diverse tipologie di medaglie. Più precisamente, si deve costruire un dataset con tre variabili contenenti, rispettivamente, la proporzione di medaglie d’oro, d’argento e di bronzo vinte da ciascun paese.\n\n\n\nSoluzione\nmedals_composition &lt;- \n  subset(Olympics, \n         TotalMedals &gt; 0,\n         select=c(Gold, Silver, Bronze))\n\nmedals_composition &lt;- t(apply(medals_composition, 1, function(x) x/sum(x)))\n\n\n\nUna caratteristica dei dati composizionali è che ogni unità statistica è associata ad un vettore con elementi positivi, i quali sommano a 1. Si verifichino queste due caratteristiche in merito al dataset medals_composition.\n\n\n\nSoluzione\nall(apply(medals_composition, 1, function(x) all(x &gt;= 0)))\n\nall(rowSums(medals_composition) == 1)\n\n\n\nSi noti che, per via del vincolo di somma a 1, la matrice di varianze e covarianze di dati composizionali è a rango non pieno. Infatti, è possibibile dimostrare che la somma di ogni riga (o di ogni colonna) vale 0.\nSi ottenga la matrice di varianze e covarianze del dataset medals_composition e si verifichi tale proprietà.\n\n\n\nSoluzione\nSigma &lt;- cov(medals_composition)\n\ncolSums(Sigma)\nrowSums(Sigma)\n\n\n\n\nEsercizio 2.5\nSi importi il dataset animals.csv, scaricabile al seguente link, contenente informazioni su 38 specie di animali. In particolare, il dataset contiene le seguenti variabili:\n\nspecie_tr: specie dell’animale;\npeso_corpo: peso del corpo, in Kg;\npeso_cerv: peso del cervello, in grammi;\nleggero: numero di ore di sonno leggero (ore al giorno);\nprofondo: numero di ore di sonno profondo (ore al giorno);\nanni_vita: speranza di vita alla nascita, in anni;\ngestazione: tempo di gestazione, in giorni;\npreda: indice qualitativo di predazione (0 = raramente è una preda, 1 = è molto spesso una preda);\nesposto: indice qualitativo di esposizione durante il sonno (0 = poco esposto, 1 = molto esposto);\npericolo: indice qualitativo di pericolo (0 = gli altri animali non rappresentano un pericolo per lui, 1 = gli altri animali rappresentano un grave pericolo per lui).\n\n\nConvertire le variabili qualitative in factor.\n\n\n\nSoluzione\nanimals &lt;- read.table(\"animals.csv\", header = T, sep = \";\")\n\n\n\nanimals$preda &lt;- as.factor(animals$preda)\nanimals$esposto &lt;- as.factor(animals$esposto)\nanimals$pericolo &lt;- as.factor(animals$pericolo)\n\n\n\nSi aggiunga al dataset la nuova variabile sonno, rappresentante il numero totale di ore di sonno giornaliere.\n\n\n\nSoluzione\nanimals$sonno &lt;- animals$leggero + animals$profondo\n\n\n\nQuale animale dorme complessivamente di più? E quale dorme di meno?\n\n\n\nSoluzione\nanimals$specie_tr[which.max(animals$sonno)]\nanimals$specie_tr[which.min(animals$sonno)]\n\n\n\nSi ottenga il quantile di ordine 0.6 della variabile sonno e lo si interpreti.\n\n\n\nSoluzione\nquantile(animals$sonno, probs = .6)\n\n\n\nSi proponga un opportuno grafico per studiare la relazione tra sonno e peso_cerv. Si commenti il risultato ottenuto.\n\n\n\nSoluzione\nplot(animals$sonno ~ animals$peso_cerv, pch = 20, \n     main = \"Sonno - Peso Cervello\", xlab = \"Peso cervello\", ylab = \"Sonno\")\n\n\n\nSi proponga un opportuno grafico per studiare la relazione tra sonno e preda. Si commenti il risultato ottenuto.\n\n\n\nSoluzione\nboxplot(animals$sonno ~ animals$preda, pch = 20, \n        main = \"Sonno - Preda\", xlab = \"Preda\", ylab = \"Sonno\")\n\n\n\nSi ritiene possibile costruire un grafico per studiare la relazione tra sonno e peso_cerv, tenendo conto anche della presenza della variabile preda? Se si, si riporti tale grafico e lo si commenti. Altrimenti, si motivi il perché non lo si ritiene possibile.\n\n\n\nSoluzione\nplot(animals$sonno ~ animals$peso_cerv, col = animals$preda, \n     pch = 20, main = \"Sonno - Peso Cervello\", \n     xlab = \"Peso cervello\", ylab = \"Sonno\")\n\nlevels(animals$preda)\n# neri: 0\n# rossi: 1\n\n\n\n\nEsercizio 2.6\nSi importi in memoria il dataset datasaurus.csv, scaricabile al seguente link, contenente tre colonne:\n\nx e y, che rappresentano coordinate cartesiane;\ndataset, che identifica il gruppo di appartenenza di ciascuna riga.\n\nOgni sottoinsieme di righe con lo stesso valore nella colonna dataset costituisce un dataset distinto. Ad esempio, tutte le righe con dataset pari a \"ABC\" compongono il dataset denominato \"ABC\".\n\nSi rimuovano dal data.frame tutte le righe che fanno riferimento al dataset \"slant_down\".\n\n\n\nSoluzione\ndatasaurus &lt;- \n  read.table(\"datasaurus.csv\", sep = \",\", header = T)\n\ndatasaurus2 &lt;- \n  subset(datasaurus, dataset != \"slant_down\")\n\n\n\nQuante modalità assume adesso la variabile dataset? Si salvi questo valore in un oggetto chiamato D.\n\n\n\nSoluzione\nD &lt;- length(unique(datasaurus2$dataset)); D\n\n\n\nSi vogliono studiare alcune statistiche di sintesi (\\(\\bar{x}, \\bar{y}, s^2_{x}, s^2_{y}\\) e \\(\\rho_{x,y}\\)) per ognuno dei D dataset. Si salvino queste statistiche in una matrice stat_sintesi avente 5 colonne (i.e., le 5 statistiche di sintesi) e D righe (i.e., i D dataset).\n\n\n\nSoluzione\nstat_sintesi &lt;- matrix(NA, ncol = 5, nrow = D)\n\ncolnames(stat_sintesi) &lt;- c(\"Media_X\", \"Media_Y\",\n                            \"Var_X\", \"Var_Y\", \"Cov_XY\")\n\n\nfor(d in 1:D){\n  data_sub &lt;- subset(datasaurus2, dataset == unique(datasaurus2$dataset)[d])\n  \n  stat_sintesi[d,1] &lt;- mean(data_sub$x)\n  stat_sintesi[d,2] &lt;- mean(data_sub$y)\n  stat_sintesi[d,3] &lt;- var(data_sub$x)\n  stat_sintesi[d,4] &lt;- var(data_sub$y)\n  stat_sintesi[d,5] &lt;- cov(data_sub$x, data_sub$y)\n}\n\nstat_sintesi\n\n\n\nSi imposti una finestra grafica che possa contenere D grafici. Si ottengano i diagrammi a dispersione delle variabili x e y per ciascuno dei dataset. Che conclusione possiamo trarre dall’analisi congiunta di stat_sintesi e del grafico appena costruito?\n\n\n\nSoluzione\npar(mfrow=c(3,4))\nfor(d in 1:D){\n  \n  data_sub &lt;- subset(datasaurus2, dataset == unique(datasaurus2$dataset)[d])\n  \n  plot(data_sub$x, data_sub$y, pch = 20, main = unique(datasaurus2$dataset)[d])\n}\npar(mfrow=c(1,1))"
  },
  {
    "objectID": "Esercizi.html#parte-3-probabilità",
    "href": "Esercizi.html#parte-3-probabilità",
    "title": "Esercizi R",
    "section": "Parte 3: Probabilità",
    "text": "Parte 3: Probabilità\n\nEsecizio 3.1\n\nSi rappresentino graficamente e sullo stesso grafico le funzioni di densità di una variabile casuale \\(\\chi^2_g\\) con \\(g \\in \\{1, 2, 5, 10\\}\\), differenziando le linee delle curve a piacere. Si costruisca anche un’opportuna legenda.\n\n\n\nSoluzione\ncurve(dchisq(x, 1), xlim=c(0,40))\ncurve(dchisq(x, 2), add = T, col=\"red\", lty=\"dashed\")\ncurve(dchisq(x, 5), add = T, col=\"blue\", lty=\"dotted\")\ncurve(dchisq(x, 10), add = T, col=\"green\", lty=\"dotdash\")\nlegend(20, .5, \n       c(\"g = 1\",\"g = 2\",\"g = 5\",\"g = 10\"),\n       col=c(\"black\",\"red\",\"blue\",\"green\"),\n       lty=c(\"solid\",\"dashed\",\"dotted\",\"dotdash\"),\n    bty=\"n\")\n\n\n\nSi ricorda che se \\(Y \\sim Gamma(g/2, 1/2)\\), allora \\(Y \\sim \\chi^2_g\\). Si fissi \\(g = 50\\) e si estraggano 5000 valori da una \\(Gamma(g/2, 1/2)\\) e si confronti la distribuzione empirica ottenuta con quella di una \\(\\chi^2_g\\).\n\n\n\nSoluzione\nset.seed(42)\ng &lt;- 50\ngamma &lt;- rgamma(5000, g/2, rate = .5)\n\npar(mfrow=c(1,2))\nhist(gamma, prob = T, main = \"Istogramma valori estratti da Gamma\")\ncurve(dchisq(x, g), col = 2, add = T)\nplot(ecdf(gamma))\ncurve(pchisq(x, g), col = 2, add = T)\npar(mfrow=c(1,1))\n\n\n\nSi ricorda che se \\(X_1, \\dots, X_g\\) sono i.i.d. e \\(X_j \\sim N(0,1)\\), allora \\(\\displaystyle \\sum_{j=1}^g X_j^2 \\sim \\chi^2_g\\). Si usi questo risultato teorico per ottenere un campione di 8000 valori da una \\(\\chi^2_{10}\\) sfruttando unicamente la funzione rnorm().\n\n\n\nSoluzione\nB &lt;- 8000\ng &lt;- 10\n# Tanti, tanti modi. Ne vediamo due:\n\n# Primo, poco efficiente:\nchi2_10_primo &lt;- numeric(B)\n\nset.seed(42)\nfor(b in 1:B){\n  chi2_10_primo[b] &lt;- sum(rnorm(g, mean = 0, sd = 1)^2)\n}\n\n\n# Secondo:\nvalori_normale &lt;- matrix(rnorm(B*g)^2, ncol = g, nrow = B)\nchi2_10_secondo &lt;- rowSums(valori_normale)\n\npar(mfrow=c(1,2))\nhist(chi2_10_primo, prob = T, main=\"Proposta 1\")\ncurve(dchisq(x, g), add = T, col = \"red\")\n\nhist(chi2_10_secondo, prob = T, main=\"Proposta 2\")\ncurve(dchisq(x, g), add = T, col = \"red\")\npar(mfrow=c(1,1))\n\n\n\nNell’inferenza è spesso necessario ricavare dei quantili di una \\(\\chi^2_g\\). Si utilizzi R per ottenere il quantile di ordine 0.95 di una \\(\\chi^2_{10}\\) in due modi differenti, uno esatto ed uno approssimato.\n\n\n\nSoluzione\nqchisq(.95, 10)\n\nquantile(chi2_10_primo, probs = .95)\n\n\n\n\nEsercizio 3.2 (difficile):\nIn una foresta incantata, alla fine del giorno 0 vengono piantati 6 semi magici. Dal giorno 1 in avanti, alla fine di ogni giornata, ogni seme ha una probabilità pari a 0.5 di trasformarsi in un albero. Una volta trasformato, esso resterà un albero per sempre.\nSi implementi una simulazione per approssimare il numero atteso (medio) di giorni necessari affinchè tutti i semi diventino degli alberi.\nLa fonte dell’esercizio e la sua risoluzione analitica possono essere trovati in questo video.\n\n\nSoluzione\nn &lt;- 6\nnsim &lt;- 50000\n\ndays &lt;- numeric(nsim)\nfor(s in 1:nsim){\n  tree &lt;- numeric(n)\n  d &lt;- 0 # giorno 0\n  succ &lt;- 0 # quanti semi sono diventati alberi\n  \n  while(succ &lt; 6){\n    tree[which(tree==0)] &lt;- rbinom(sum(tree==0),1,.5)\n    succ &lt;- sum(tree)\n    d &lt;- d+1\n  }\n  days[s] &lt;- d\n}\n\nmean(days)\n\n# Oppure:\nmean(replicate(nsim, max(rgeom(6,0.5))+1))\n\n\n\n\nEsercizio 3.3\nSiano \\(p_1(x)\\) e \\(p_2(x)\\) due funzioni di probabilità associate a due variabili casuali discrete \\(X_1\\) e \\(X_2\\) caratterizzate sullo stesso supporto \\(\\mathcal{S} = \\{x_1, \\dots, x_k\\}\\). La divergenza di Kullback-Leibler di \\(X_1\\) da \\(X_2\\) è definita come \\(KL(p_1 || p_2) = \\displaystyle \\sum_{j=1}^k p_1(x_j) \\log \\left(\\frac{p_1(x_j)}{p_2(x_j)}\\right).\\)\n\nSi calcoli il valore della divergenza di Kullback-Leibler di \\(X_1\\) da \\(X_2\\) considerando \\(X_1\\) e \\(X_2\\) distribuite come Binomiali di parametro \\(n = 20\\) e probabilità di successo rispettivamente \\(\\theta_1 = 0.2\\) e \\(\\theta_2 = 0.1\\).\n\n\n\nSoluzione\nn &lt;- 20\ntheta1 &lt;- 0.2\ntheta2 &lt;- 0.1\n\np1 &lt;- dbinom(0:n, n, theta1)\np2 &lt;- dbinom(0:n, n, theta2)\n\nsum(p1*log(p1/p2))\n\n\n\nLa divergenza di Kullback-Leibler gode della proprietà di simmetria?\n\n\n\nSoluzione\nn &lt;- 20\ntheta1 &lt;- 0.2\ntheta2 &lt;- 0.1\n\np1 &lt;- dbinom(0:n, n, theta1)\np2 &lt;- dbinom(0:n, n, theta2)\n\nKL_x1_da_x2 &lt;- sum(p1*log(p1/p2))\nKL_x2_da_x1 &lt;- sum(p2*log(p2/p1))\n\nKL_x1_da_x2; KL_x2_da_x1\n\n\n\nSi calcoli la stessa quantità del punto 1 facendo variare \\(\\theta_2 \\in \\{0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.9\\}\\). Da questi risultati è possibile intuire quale aspetto viene misurato da questo indice?\n\n\n\nSoluzione\nn &lt;- 20\ntheta1 &lt;- 0.2\ntheta2_vec &lt;- c(.05, .1, .2, .3, .5, .7, .9)\n\np1 &lt;- dbinom(0:n, n, theta1)\n\nKL &lt;- numeric(length(theta2_vec))\n\nfor(i in 1:length(theta2_vec)){\n  theta2 &lt;- theta2_vec[i]\n  \n  p2 &lt;- dbinom(0:n, n, theta2)\n\n  KL[i] &lt;- sum(p1*log(p1/p2))\n}\nplot(theta2_vec, KL)\n\n\n\nCi si convinca che \\(\\displaystyle KL(p_1 || p_2) = \\mathbb{E}\\left[\\log\\left\\{\\frac{p_1(X_1)}{p_2(X_1)} \\right\\} \\right]\\). Si utilizzi questo risultato per ottenere un’approssimazione Monte Carlo di quanto ottenuto al punto 1.\n\n\n\nSoluzione\nB &lt;- 8000\nn &lt;- 20\ntheta1 &lt;- .2\ntheta2 &lt;- .1\nKL_sim &lt;- numeric(B)\n\nfor(b in 1:B){\n  x_j &lt;- rbinom(1, n, theta1)\n  \n  KL_sim[b] &lt;- log(dbinom(x_j, n, theta1)/dbinom(x_j, n, theta2))\n}\nmean(KL_sim)\n\n\n\nSi considerino ora \\(X_1\\) e \\(X_2\\) distribuite secondo distribuzioni Poisson di parametri \\(\\lambda_1\\) e \\(\\lambda_2\\). Dato che il supporto della Poisson è illimitato, per calcolare la divergenza di Kullback-Leibler bisognerebbe calcolare una serie numerica. Si proponga almeno un modo per ottenere la divergenza di Kullback-Leibler considerando \\(\\lambda_1 = 2\\) e \\(\\lambda_2 = 10\\).\n\n\n\nSoluzione\n# Modo 1: Tronco il supporto ad un elemento sufficientemente alto\n\nlambda1 &lt;- 2\nlambda2 &lt;- 10\n\nS_X &lt;- 0:100\n\np1 &lt;- dpois(S_X, lambda1)\np2 &lt;- dpois(S_X, lambda2)\nKL &lt;- sum(p1*log(p1/p2))\n\n\n# Modo 2: uso Monte Carlo:\n\nB &lt;- 15000\nlambda1 &lt;- 2\nlambda2 &lt;- 10\nKL_sim &lt;- numeric(B)\n\nfor(b in 1:B){\n  x_j &lt;- rpois(1, lambda1)\n  \n  KL_sim[b] &lt;- log(dpois(x_j, lambda1)/dpois(x_j, lambda2))\n}\n\nKL\nmean(KL_sim)\n\n\n\nSi replichi quanto fatto nel punto 5 considerando due distribuzioni Geometriche di probabilità pari a \\(\\pi_1 = 0.45\\) e \\(\\pi_2 = 0.9\\), rispettivamente.\n\n\n\nSoluzione\n# Modo 1: Tronco il supporto ad un elemento sufficientemente alto\n\npi1 &lt;- .45\npi2 &lt;- .9\n\nS_X &lt;- 0:100\n\np1 &lt;- dgeom(S_X, pi1)\np2 &lt;- dgeom(S_X, pi2)\nKL &lt;- sum(p1*log(p1/p2))\n\n\n# Modo 2: uso Monte Carlo:\n\nB &lt;- 15000\npi1 &lt;- .45\npi2 &lt;- .9\nKL_sim &lt;- numeric(B)\n\nx &lt;- rgeom(B, pi1)\n\nKL_sim &lt;- log(dgeom(x, pi1)/dgeom(x, pi2))\n\nKL\nmean(KL_sim)\n\n\n\n\nEsercizio 3.4\nIn un popolare gioco di ruolo, giocatori e giocatrici devono lanciare dei dadi a 20 facce per superare delle prove.\nPer superare la prima prova, viene chiesto di lanciare \\(K\\) dadi a 20 facce. La prova si ritiene superata se almeno \\(L\\) dei \\(K\\) dadi presenta valore maggiore di 13.\n\nSi scriva una funzione prova1(K, L, B) che approssimi, tramite una simulazione basata su B repliche, la probabilità di superare la prova.\n\n\n\nSoluzione\nprova1 &lt;- function(K, L, B=2000){\n  successo &lt;- numeric(B)\n  \n  for(b in 1:B){\n    dadi &lt;- sample(1:20, K, replace=T)\n    dadi_vincenti &lt;- sum(dadi &gt; 13)\n    successo[b] &lt;- dadi_vincenti &gt; L\n  }\n  \n  return(mean(successo))\n}\n\n\n\nSi utilizzi la funzione definita al punto precedente considerando i valori \\(K = 10\\), \\(L = 6\\) e \\(B = 50000\\) per approssimare la probabilità di superare la prima prova.\n\n\n\nSoluzione\nprova1(10, 5, B=50000)\n\n\n\nSi consideri la variabile casuale \\(X\\) definita dal numero di dadi che hanno portato ad un valore maggiore di 13 tra i \\(K\\) lanciati. Si ottenga una rappresentazione grafica della funzione di probabilità di \\(X\\).\n\n\n\nSoluzione\nK &lt;- 10\nB &lt;- 50000\nsupporto &lt;- 0:K\nesiti &lt;- numeric(B)\n\nfor(b in 1:B){\n  dadi &lt;- sample(1:20, K, replace=T)\n  dadi_vincenti &lt;- sum(dadi &gt; 13)\n  esiti[b] &lt;- dadi_vincenti\n}\n\ntable(esiti)/B\n\nplot(table(esiti)/B, main = \"Distribuzione di probabilità di X\", ylab=\"Prob. (approx.)\")\n\n\n\n\nEsercizio 3.5\nLa variabile casuale Weibull, molto utilizzata nella teoria dei valori estremi, è caratterizzata dalla seguente funzione di densità:\n\\[ f(y; \\alpha, \\beta) = \\alpha \\beta y^{\\beta - 1} e^{-\\alpha y^\\beta},\\] se \\(y &gt; 0\\), dove \\(\\alpha\\) e \\(\\beta\\) sono due parametri positivi.\n\nSi scriva una funzione in R chiamata my_dweibull che calcoli la funzione di densità di una Weibull.\n\n\n\nSoluzione\nmy_dweibull &lt;- function(x, alpha, beta){\n  dens &lt;- alpha*beta*(x^(beta-1))*exp(-alpha*(x^beta))\n  return(dens)\n}\n\nmy_dweibull(4, 1, .2)\n\n\n\nSi ottenga analiticamente la funzione di ripartizione di una Weibull e la si implementi in R, creando una funzione my_pweibull.\n\n\n\nSoluzione\n\nLa funzione di ripartizione può essere ottenuta risolvendo il seguente integrale: \\(F(t; \\alpha, \\beta) = \\displaystyle \\int_0^t \\alpha \\beta y^{\\beta - 1} e^{-\\alpha y^\\beta} dy\\).\nTramite sostituzione \\((s = y^\\beta, ds = \\beta y^{\\beta -1} dy)\\), si ottiene \\(\\displaystyle F(t; \\alpha, \\beta) = \\int_0^{t^\\beta} \\alpha  e^{-\\alpha s} ds = 1 - e^{-\\alpha t^\\beta}\\).\n\nmy_pweibull &lt;- function(q, alpha, beta){\n  rip &lt;- ifelse(q &lt; 0, 0, 1 - exp(-alpha * (q^beta)))\n  return(rip)\n}\n\nmy_pweibull(4, 1, .2)\n\n\n\nSi ottenga analiticamente la funzione quantile (inversa della funzione di ripartizione) di una Weibull e la si implementi in R, creando una funzione my_qweibull.\n\n\n\nSoluzione\n\nPer ottenere la funzione quantile è necessario invertire la funzione di ripartizione ottenuta al punto precedente: \\(\\displaystyle Q(u) = F^{-1}(u), u \\in (0,1)\\). Isolando \\(t\\) dall’espressione \\(1- e^{-\\alpha t^\\beta}\\), si ottiene \\(Q(u) = \\left[ -\\frac{1}{\\alpha} \\log(1-u) \\right]^{1/\\beta}\\).\n\nmy_qweibull &lt;- function(u, alpha, beta){\n  q &lt;- (-alpha^(-1) * log(1-u))^(1/beta)\n  return(q)\n}\n\nmy_qweibull(.73, 1, .2)\n\n\n\nSi utilizzi il metodo della trasformata inversa per creare una funzione my_rweibull per generare n valori pseudo-casuali da una Weibull.\n\n\n\nSoluzione\nmy_rweibull &lt;- function(n, alpha, beta){\n  sample &lt;- numeric(n)\n  \n  for(i in 1:n){\n    sample[i] &lt;- my_qweibull(u = runif(1), alpha, beta)\n  }\n  return(sample)\n}\n\n\n\nSi verifichi che la funzione my_rweibull permette di estrarre valori pseudo-casuali dalla funzione di densità in analisi. (Si scelgano dei valori arbitrari per \\(\\alpha\\) e \\(\\beta\\).)\n\n\n\nSoluzione\nn &lt;- 8000\nsample &lt;- my_rweibull(n, 5, 2)\n\npar(mfrow=c(1,2))\nhist(sample, prob = T)\ncurve(my_dweibull(x, 5, 2), add=T, col = 2)\nplot(ecdf(sample))\ncurve(my_pweibull(x, 5, 2), add=T, col = 2)\npar(mfrow=c(1,1))\n\n\n\n\nEsercizio 3.6\nSi consideri una variabile casuale discreta \\(X\\) con supporto \\(\\mathcal{S}_X = \\{2, 4, 6, 8, 10, 12\\}\\) e funzione di probabilità: \\(\\displaystyle p(x) = \\frac{1}{441} \\left(\\frac{x}{2} \\right)^3, x \\in \\mathcal{S}_X\\).\n\nSi verifichi che la funzione \\(p(x)\\) è una funzione di probabilità.\n\n\n\nSoluzione\nS_X &lt;- 2*(1:6)\np_x &lt;- (1/441)*(S_X/2)^3\n\nsum(p_x)\n\n\n\nSi propongano due metodi per estrarre n valori pseudo casuali da \\(X\\).\n\n\n\nSoluzione\nn &lt;- 8000\n\n# Metodo 1:\nset.seed(369)\n\naa &lt;- cumsum(c(0, p_x))\n\nu &lt;- runif(n)\nsample1 &lt;- S_X[as.numeric(cut(u, aa))]\n\n# Metodo 2:\nsample2 &lt;- sample(S_X, n, replace = T, prob = p_x)\n\n\n\nSi proponga un modo per verificare se i metodi proposti sembrano generare valori proprio dalla distribuzione desiderata.\n\n\n\nSoluzione\nround(cbind(p_x, \n            table(sample1)/n, \n            table(sample2)/n), 4)\n\n\n\nSi usi uno dei campioni ottenuti per approssimare il valore atteso, il momento secondo e la varianza di \\(X\\).\n\n\n\nSoluzione\nmu &lt;- mean(sample1)\nmom2 &lt;- mean(sample1^2)\nvar &lt;- mean((sample1-mean(sample1))^2)\n# Oppure \n#var &lt;- mom2 - mu^2\n\n\n\n\nEsercizio 3.7\nSi estragga un campione di ampiezza \\(n = 200\\) da una Normale con media \\(\\mu = 15\\) e varianza \\(\\sigma^2 = 20\\).\n\n\nSoluzione\nn &lt;- 200\nmu &lt;- 15\nsigma2 &lt;- 20\n\nset.seed(678)\ny &lt;- rnorm(n, mu, sqrt(sigma2))\n\n\n\nSi considerino \\(\\mu\\) e \\(\\sigma^2\\) entrambi ignoti e si fornisca una stima per entrambi i parametri. Qual è l’errore commesso dai due stimatori, in questo caso?\n\n\n\nSoluzione\nmu_hat &lt;- mean(y); mu_hat\nsigma2_hat &lt;- var(y); sigma2_hat\n\nmu - mu_hat\nsigma2 - sigma2_hat\n\n\n\nSi vuole sottoporre a verifica \\(H_0: \\mu = 5\\) vs. \\(H_1: \\mu \\neq 5\\) ad un livello \\(\\alpha = 0.05\\). Si determini la conclusione inferenziale, ricorrendo alla regione critica.\n\n\n\nSoluzione\nmu_star &lt;- 5\nalpha &lt;- 0.05\n\nstat_test &lt;- (mu_hat - mu_star)/sqrt(sigma2_hat/n)\n\nsoglia &lt;- qt(1 - (alpha/2), n - 1)\n\nifelse(abs(stat_test) &gt;= abs(soglia), \"Rifiuto H0\", \"Non rifiuto H0\")\n\n\n\nSi risolva il punto precedente ricorrendo al concetto di p-value.\n\n\n\nSoluzione\np_value &lt;- pnorm(-abs(stat_test)); p_value\n\nifelse(p_value &lt; alpha, \"Rifiuto H0\", \"Non rifiuto H0\")\n\n\n\n\nEsercizio 3.8\nUna distribuzione (multivariata) per dati composizionali è la distribuzione Dirichlet. Siano \\(\\displaystyle \\textbf{x} = (x_1, \\dots, x_D)^\\intercal \\in \\mathcal{S}^D = \\left\\{ \\textbf{x} = (x_1, \\dots, x_D)^\\intercal : x_d &gt; 0, \\sum_{d=1}^D x_d = 1\\right\\}\\), \\(\\boldsymbol{\\alpha} = (\\alpha_1, \\dots, \\alpha_D)^\\intercal\\) un vettore \\(D\\)-dimensionale con elementi positivi e \\(\\displaystyle \\alpha^+ = \\sum_{d=1}^D \\alpha_d\\); allora la funzione di densità congiunta della Dirichlet è data da \\[\\displaystyle f(\\textbf{x}; \\boldsymbol{\\alpha}) = \\frac{\\Gamma(\\alpha^+)}{\\prod_{d=1}^D \\Gamma(\\alpha_d)} \\prod_{d=1}^D x_d^{\\alpha_d - 1},\\] se \\(\\textbf{x}\\in\\mathcal{S}^D\\) e 0 altrimenti.\n\nSi implementi una funzione ddir che permetta di calcolare la densità congiunta di un vettore composizionale \\(\\textbf{x}\\) e la si valuti nel punto \\(\\textbf{x} = (.2, .1, .4, .05, .25)^\\intercal\\) con \\(\\boldsymbol{\\alpha} = (4, 1, 10, 5, 2)^\\intercal\\).\n\n\n\nSoluzione\nddir &lt;- function(x, alpha){\n  aplus &lt;- sum(alpha)\n  \n  dens &lt;- gamma(aplus)/(prod(gamma(alpha)))* prod(x^(alpha-1))\n  \n  return(dens)\n}\n\nx &lt;- c(.2, .1, .4, .05, .25)\nalpha &lt;- c(4, 1, 10, 5, 2)\n\nddir(x, alpha)\n\n\n\nSiano \\(Y_1, \\dots Y_D\\) delle variabili casuali indipendenti tali che \\(Y_d \\sim Gamma(\\alpha_d, 1)\\). Definendo \\(\\displaystyle Y^+ = \\sum_{d=1}^D Y_d\\), si può dimostrare che \\(\\displaystyle (Y_1 / Y^+, \\dots, Y_D/Y^+)^\\intercal \\sim Dirichlet(\\boldsymbol{\\alpha})\\). Si utilizzi questa relazione per costruire un oggetto (vettore? matrice? lista? altro?) sample_dir contenente B = 5000 dati composizionali pseudo-casuali da una Dirichlet con \\(D = 5\\) e \\(\\boldsymbol{\\alpha} = (4, 2, 10, 5, 3)^\\intercal\\).\n\n\n\nSoluzione\nD &lt;- 5\nB &lt;- 5000\n\nalpha &lt;- c(4, 2, 10, 5, 3)\ny_matrix &lt;- matrix(NA, ncol = D, nrow = B)\n\nfor(d in 1:D){\n  y_matrix[,d] &lt;- rgamma(B, alpha[d], 1)\n}\n\nsample_dir &lt;- t(apply(y_matrix, 1, function(x) x/sum(x)))\n\n\n\nSi confronti la distribuzione del terzo elemento di sample_dir con quella di una \\(Beta(\\alpha_3, \\alpha^+ - \\alpha_3)\\). Si commenti questo confronto, facendo autonomamente una ricerca sul legame che intercorre tra queste due distribuzioni.\n\n\n\nSoluzione\npar(mfrow=c(1, 2))\nhist(sample_dir[,3], main = \"Istogramma X_3\", prob = T)\ncurve(dbeta(x, alpha[3], sum(alpha) - alpha[3]), col = \"red\", add = T)\n\nplot(ecdf(sample_dir[,3]))\ncurve(pbeta(x, alpha[3], sum(alpha) - alpha[3]), col = \"red\", add = T)\npar(mfrow=c(1, 1))\n\n\n\n\nEsercizio 3.9\nSi supponga di essere interessato ad approssimare, mediante il metodo Monte Carlo, il valore del seguente integrale: \\[\\int_{-\\infty}^{+\\infty} \\frac{f(x)}{g(x)} \\phi(x) dx,\\] dove \\(\\phi(x)\\) rappresenta la funzione di densità di una Normale standard.\n\nSi dica perché il seguente funzione non porta ad una soluzione corretta.\n\n\nmy_integral &lt;- function(B = 5000) {\n  int &lt;- mean(f(rnorm(B)) / g(rnorm(B)))\n  \n  return(int)\n}\n\n\nSi costruisca una funzione che permetta di calcolare il corretto valore dell’integrale proposto.\n\n\n\nSoluzione\nmy_integral_2 &lt;- function(B = 5000) {\n  y &lt;- rnorm(B)\n  int &lt;- mean(f(y) / g(y))\n  \n  return(int)\n}\n\n\n\nSi considerino le funzioni \\(f(x) = \\sqrt{|x|}\\) e \\(g(x) = x^2 + 1\\). Si calcoli il valore dell’integrale con gli approcci del punto 1 e punto 2 e li si confronti con il risultato della funzione integrate.\n\n\n\nSoluzione\nmy_integral &lt;- function(B = 5000) {\n  int &lt;- mean(sqrt(abs(rnorm(B))) / (rnorm(B)^2+1))\n  \n  return(int)\n}\n\nmy_integral_2 &lt;- function(B = 5000) {\n  \n  y &lt;- rnorm(B)\n  \n  int &lt;- mean(sqrt(abs(y)) / (y^2+1))\n  \n  return(int)\n}\n\nmy_integral()\nmy_integral_2()\n\nintegrate(function(x) sqrt(abs(x))/(x^2+1) * dnorm(x), lower=-Inf, upper=Inf)\n\n\n\n\nEsercizio 3.10\nSi consideri la variabile casuale continua Half-Normal, caratterizzata dalla seguente funzione di densità:\n\\[f(y) = \\sqrt{\\frac{2}{\\pi}} \\exp\\lbrace-y^2/2\\rbrace,\\] se y &gt; 0.\nQuesta variabile casuale può essere vista come trasformazione di una Normale Standard: se \\(Z \\sim N(0,1)\\), allora \\(Y = |Z| \\sim\\) Half-Normal.\n\nScrivere una funzione in R chiamata dhalf che calcoli la funzione di densità di una Half-Normal.\n\n\n\nSoluzione\ndhalf &lt;- function(y) sqrt(2/pi)*exp(-y^2/2)\n\n\n\nSi sviluppi una strategia che permetta di generare valori pseudo-casuali da \\(Y\\).\n\n\n\nSoluzione\nB &lt;- 10000\n\ny &lt;- abs(rnorm(B))\n\n\n\nConfrontare l’istogramma di 10000 valori pseudo-casuali generati da una Half-Normal con la relativa funzione di densità.\n\n\n\nSoluzione\nhist(y, prob = T, main = \"Istogramma Half-Normal\")\ncurve(dhalf(y = x), col = 2, add = T)\n\n\n\nSi approssimi il valore atteso di una Half-Normal.\n\n\n\nSoluzione\nmean(y)"
  },
  {
    "objectID": "Esercizi.html#parte-4-inferenza",
    "href": "Esercizi.html#parte-4-inferenza",
    "title": "Esercizi R",
    "section": "Parte 4: Inferenza",
    "text": "Parte 4: Inferenza\n\nEsercizio 4.1\nSia \\(Y_1, \\dots, Y_n\\) un campione casuale semplice estratto da una Esponenziale di media 5.\n\nSi ottengano 4 realizzazioni campionarie di ampiezza \\(n \\in \\{10, 50, 100, 1000\\}\\), salvandoli all’interno di una lista.\n\n\n\nSoluzione\nn &lt;- c(10, 50, 100, 1000)\ny &lt;- list()\n\nfor(i in 1:4){\n  y[[i]] &lt;- rexp(n[i], rate = 1/5)\n}\n\n\n\nSi ottengano le stime di massima verosimiglianza (MV) per i 4 campioni considerati, misurando l’errore di stima commesso.\n\n\n\nSoluzione\nstime &lt;- numeric(4)\n\nfor(i in 1:4){\n  stime[i] &lt;- mean(y[[i]])\n}\n\nstime - 5\n\n\n\nSi implementi uno studio di simulazione per verificare empiricalmente la convergenza in distribuzione dello stimatore MV. Per ciascuna delle 4 numerosità campionarie considerate, si considerino 10000 repliche.\n\n\n\nSoluzione\nB &lt;- 10000\nstime_n &lt;- matrix(NA, ncol = length(n), nrow = B)\ncolnames(stime_n) &lt;- n\n\npar(mfrow=c(2,2))\nfor(i in 1:length(n)){\n  for(b in 1:B){\n    y &lt;- rexp(n[i], rate = 1/5)\n    \n    stime_n[b,i] &lt;- mean(y)\n  }\n  hist(stime_n[,i], prob = T, \n       main = paste(\"Distr. media camp. con n = \", n[i], sep=\"\"), xlab = \"stima\")\n  curve(dnorm(x, 5, sqrt((5^2)/n[i])), col = 2, add = T)\n}\npar(mfrow=c(1,1))\n\n\n\nSi valuti empiricamente la consistenza dello stimatore MV.\n\n\n\nSoluzione\nboxplot(stime_n)\nabline(h = 5, col = 2)\n\n\n\nCome varia l’MSE (mean squared error) all’aumentare di \\(n\\)?\n\n\n\nSoluzione\nMSE &lt;- apply(stime_n, 2, function(x) mean((x-5)^2))\nplot(n, MSE, pch = 20)\nabline(h = 0, col = 2)\n\n\n\n\nEsercizio 4.2\nSi consideri un campione casuale di ampiezza \\(n\\) estratto da una popolazione Normale di parametri \\(\\mu\\) e \\(\\sigma^2\\). Si scelgano a piacere dei valori per gli ignoti parametri e si generi un campione di ampiezza \\(n = 35\\).\n\n\nSoluzione\nn &lt;- 35\n\nmu &lt;- 13\nsigma2 &lt;- 5\n\nset.seed(42)\ny &lt;- rnorm(n, mu, sqrt(sigma2))\n\n\n\nSi consideri \\(\\sigma^2\\) noto e pari al vero valore scelto. Si implementi la funzione loglik_mu(mu, y) che permetta di calcolare la funzione di log-verosimiglianza. Si rappresenti graficamente tale funzione in un opportuno intervallo.\n\n\n\nSoluzione\nloglik_mu &lt;- function(mu, y){\n  sum(log(dnorm(y, mu, sqrt(sigma2))))\n}\n\nloglik_mu &lt;- Vectorize(loglik_mu, vectorize.args = \"mu\")\n\ncurve(loglik_mu(mu = x, y), xlim = c(0, 25))\n\n\n\nNonostante si conosca la forma della stima MV per \\(\\mu\\), si utilizzi una procedura di ottimizzazione numerica per ottenerla.\n\n\n\nSoluzione\nMV_mu &lt;- nlminb(start = 0,\n       objective = function(x) -loglik_mu(x, y))\nMV_mu$par\nmean(y)\n\n\n\nAdesso si consideri ignoto anche il parametro \\(\\sigma^2\\). Si implementi la funzione loglik_mu_sigma2(mu, y) che permetta di calcolara la funzione di log-verosimiglianza per entrambi i parametri. Si rappresenti graficamente questa funzione.\n\n\n\nSoluzione\nloglik_mu_sigma2 &lt;- function(par, y){\n  mu &lt;- par[1]\n  sigma2 &lt;- par[2]\n  sum(log(dnorm(y, mu, sqrt(sigma2))))\n}\n\ngriglia_mu &lt;- seq(-5, 25, by = 0.1)\ngriglia_sigma2 &lt;- seq(0.01, 10, by = 0.01)\n\ngriglia_parametri &lt;- expand.grid(griglia_mu, griglia_sigma2)\n\nlog_lik_values &lt;- apply(griglia_parametri, 1, function(x) loglik_mu_sigma2(x, y))\n\nlog_lik_values &lt;- matrix(log_lik_values, nrow = length(griglia_mu), \n                         ncol = length(griglia_sigma2), byrow = F)\n\n# Per ottenere un grafico più leggibile,\n# traspongo affinché abbia mu su asse y \n# e sigma2 su asse x.\nlog_lik_values &lt;- t(log_lik_values)\n\ncontour(x = griglia_sigma2, \n        y = griglia_mu, \n        z = log_lik_values,\n        nlevels = 30,\n        xlab = expression(sigma2),\n        ylab = expression(mu),\n        col = 4)\n\n# Noto che aumentando nlevels, si aggiungono curve nella parte iniziale del grafico,\n# ma queste curve aggiuntive non mi aiutano a comprendere il grafico. \n# Scelgo io dei livelli basandomi sui valori osservati di log_lik_values.\n\nllog_unique &lt;- unique(log_lik_values[which(log_lik_values != -Inf)])\n\nlevels &lt;- quantile(llog_unique, probs=c(seq(.05,.95,.05),.96,.97,.98,.99))\n\ncontour(x = griglia_sigma2, \n        y = griglia_mu, \n        z = log_lik_values,\n        levels = levels,\n        xlab = expression(sigma2),\n        ylab = expression(mu),\n        col = 4)\n\n\n\nSi utilizzi una procedura di ottimizzazione numerica per ottenere la stima ML degli ignoti parametri.\n\n\n\nSoluzione\nMV_mu_sigma2 &lt;- nlminb(start = c(0,1),\n       objective = function(x) -loglik_mu_sigma2(x, y))\nMV_mu_sigma2$par\nmean(y)\nvar(y)\n\n\n\nSi riportino, sul grafico ottenuto al punto 3, due punti corrispondenti al vero valore dei parametri e alla stima MV. Si commenti il grafico ottenuto, ragionando sull’eventuale distanza tra questi due punti.\n\n\n\nSoluzione\ncontour(x = griglia_sigma2, \n        y = griglia_mu, \n        z = log_lik_values,\n        levels = levels,\n        xlab = expression(sigma2),\n        ylab = expression(mu),\n        col = 4)\n\npoints(sigma2, mu, pch = 20, col = \"red\")\npoints(MV_mu_sigma2$par[2], MV_mu_sigma2$par[1], pch = 20, col = \"blue\")\n\n\n\n\nEsercizio 4.3\nSia \\(\\textbf{y} = (y_1, \\dots, y_n)^\\intercal\\) un campione di realizzazioni i.i.d. da una variabile casuale Poisson di parametro \\(\\theta &gt;0\\). La funzione di log-verosimiglianza associata a tale campione, a meno di una costante additiva, è specificata come \\[l(\\theta; \\textbf{y}) = -n\\theta + \\log(\\theta) \\sum_{i=1}^n y_i.\\]\n\nSi definisca in R una funzione loglik(theta, y) che restituisca il valore della log-verosimiglianza in corrispondenza del valore theta indicato dall’utente.\n\n\n\nSoluzione\nloglik &lt;- function(theta, y){\n  n &lt;- length(y)\n  \n  ll &lt;- -n*theta + sum(y)*log(theta)\n  return(ll)\n}\n\n\n\nD’ora in avanti si consideri il campione \\(\\textbf{y} = (5, 10,  7,  7,  9,  9,  5)^\\intercal\\). Quanto vale la funzione di log-verosimiglianza nel punto \\(\\theta = 10\\)?\n\n\n\nSoluzione\ny &lt;- c(5,10,7,7,9,9,5)\nloglik(10, y)\n\n\n\nSi utilizzi una apposita funzione di ottimizzazione numerica per calcolare la stima di massima verosimiglianza \\(\\hat{\\theta}\\). Si riporti il valore \\(\\hat{\\theta}\\).\n\n\n\nSoluzione\nres &lt;-\noptim(par = 10, # valore iniziale \n      fn = function(x) -loglik(x, y), \n      lower = 1e-5, \n      method = \"L-BFGS-B\", \n      hessian = TRUE # restituisce l'hessiana valutata nel minimo\n)\n\nres$par\nmean(y)\n\n\n\nSi rappresenti graficamente la funzione di log-verosimiglianza nell’intervallo \\((0, 15)\\). Si sovraimponga una linea verticale rossa e tratteggiata in corrispondenza della stima di massima verosimiglianza individuata al punto precedente.\n\n\n\nSoluzione\ncurve(loglik(x,y=y), xlim=c(0,15), ylab = \"loglik\", xlab = expression(theta))\nabline(v=res$par, col=\"red\", lty=\"dashed\")\n\n\n\n\nEsercizio 4.4\nSia \\(Y_1, \\dots, Y_n\\) un campione casuale estratto da una Poisson\\((\\lambda)\\). È noto che il parametro \\(\\lambda &gt;0\\) di una Poisson coincide sia con il suo valore atteso che con la sua varianza.\nDi conseguenza, due stimatori ragionevoli per \\(\\lambda\\) sono la media campionaria \\[\\displaystyle \\bar{Y} = \\frac{1}{n} \\sum_{i=1}^n Y_i\\] e la varianza campionaria non distorta \\[\\displaystyle  S^2 = \\frac{1}{n-1} \\sum_{i=1}^n \\left(Y_i - \\bar{Y} \\right)^2.\\]\n\nQuale stimatore risulta preferibile se il vero valore del parametro fosse \\(\\lambda=10\\) e se le stime fossero basate su campioni di ampiezza \\(n = 50\\)? Si risponda utilizzando un approccio basato su simulazioni.\n\n\n\nSoluzione\nB &lt;- 10000\n\nlambda_true &lt;- 10\nn &lt;- 50\n\nstime_media &lt;- numeric(B)\nstime_var &lt;- numeric(B)\n\nfor(b in 1:B){\n  x &lt;- rpois(n, lambda=lambda_true)\n  \n  stime_media[b] &lt;- mean(x)\n  stime_var[b] &lt;- var(x)\n}\n\nMSE_media &lt;- mean((stime_media - lambda_true)^2); MSE_media\nMSE_var &lt;- mean((stime_var - lambda_true)^2); MSE_var\n\n\n\nSi ottenga e si commenti una approssimazione della distribuzione dei due stimatori. Il risultato grafico è coerente con la risposta data al punto precedente?\n\n\n\nSoluzione\npar(mfrow=c(1,2))\nhist(stime_media, prob=T)\nabline(v=lambda_true, col=2, lwd=2)\nhist(stime_var, prob=T)\nabline(v=lambda_true, col=2, lwd=2)\npar(mfrow=c(1,1))\n\n\n\nSempre considerando campioni di ampiezza \\(n=50\\), si implementi uno studio di simulazione per valutare se uno dei due stimatori proposti possa ritenersi più efficiente dell’altro per ogni possibile valore di \\(\\lambda\\). Si commenti il risultato prodotto.\n\n\n\nSoluzione\nB &lt;- 5000\n# lambda può assumere infiniti valori: tronco a 50\nlambda_grid &lt;- seq(0.5, 50, by=.5)\n\nMSE_mean &lt;- numeric(length(lambda_grid))\nMSE_var &lt;- numeric(length(lambda_grid))\n\nfor(l in 1:length(lambda_grid)){\n  \n  stime_media &lt;- numeric(B)\n  stime_var &lt;- numeric(B)\n  \n  for(b in 1:B){\n    x &lt;- rpois(n, lambda=lambda_grid[l])\n    \n    stime_media[b] &lt;- mean(x)\n    stime_var[b] &lt;- var(x)\n  }\n  \n  MSE_mean[l] &lt;- mean((stime_media - lambda_grid[l])^2)\n  MSE_var[l] &lt;- mean((stime_var - lambda_grid[l])^2)\n}\n\nplot(lambda_grid, MSE_var, type=\"l\", col=1)\npoints(lambda_grid, MSE_mean, type=\"l\", col=2)\nlegend(0,90, c(\"MSE(S2)\", \"MSE(X_bar)\"), col=c(1,2), lty=\"solid\")\n\n\n\n\nEsercizio 4.5\nSiano \\(x_1, \\dots, x_n\\) delle realizzazioni i.i.d. da \\(X \\sim N(5, 15)\\). Si realizzi uno studio di simulazione che confronti la media campionaria e la media troncata di livello \\(\\alpha = 5\\%\\). Si tratta di stimatori consistenti per la media della popolazione?\nLa media troncata non considera le prime ed ultime \\(k\\) osservazioni, dove \\(k = n \\cdot\\alpha\\) (approssimato all’intero più vicino). Se \\(x_{(1)},\\dots,x_{(n)}\\) è il campione ordinato, la media troncata è quindi definita come\n\\[\n\\hat{\\mu}_\\text{tr} = \\frac{1}{n - 2 k } \\sum_{i=k+1}^{n-k} x_{(i)}.\n\\]\nIn R si può usare il comando mean(x, trim = alpha).\n\n\nSoluzione\nmu &lt;- 5 \nsigma &lt;- sqrt(15)\n\nB &lt;- 8000\n  \nn &lt;- c(5, 20, 50, 100, 200, 500)\nalpha &lt;- 0.05\n\nstime_mean &lt;- matrix(NA, ncol = length(n), nrow = B)\nstime_trimmed_mean &lt;- matrix(NA, ncol = length(n), nrow = B)\n\ncolnames(stime_mean) &lt;- paste0(\"n = \", n, sep=\"\")\ncolnames(stime_trimmed_mean) &lt;- paste0(\"n = \", n, sep=\"\")\n\nfor(b in 1:B){\n  for(j in 1:length(n)){\n    y &lt;- rnorm(n[j], mu, sigma)\n    \n    stime_mean[b,j] &lt;- mean(y)\n    stime_trimmed_mean[b,j] &lt;- mean(y, trim = alpha)\n  }\n}\n\npar(mfrow=c(2,1))\nboxplot(stime_mean, main = \"Media Campionaria\")\nabline(h = mu, col = 2, lty = \"dashed\")\nboxplot(stime_trimmed_mean, main = \"Media Campionaria Troncata\")\nabline(h = mu, col = 2, lty = \"dashed\")\npar(mfrow=c(2,1))\n\n\n\n\nEsercizio 4.6\nSi consideri un campione casuale semplice di ampiezza \\(n\\) estratto da una Normale con varianza \\(\\sigma^2\\) ignota. Si è interessati a fare inferenza sull’ignota media \\(\\mu\\) della popolazione.\nAi fini di questo esercizio e con le assunzioni fatte, si ricorda che un intervallo di confidenza a livello \\(1-\\alpha\\) per l’ignota media ha forma \\[\\bar{y} \\pm t_{n-1; 1-\\alpha/2} \\sqrt{\\frac{s^2}{n}},\\] dove \\(\\bar {y}\\) e \\(s^2\\) rapprentano rispettivamente la media e la varianza campionaria non distorta.\n\nSi consideri il campione \\(\\textbf{y} = (17.6,  8.3, 12.7, 14, 12.9, 10.5, 18.2)^\\intercal\\). Si costruisca un intervallo di confidenza a livello 98% per \\(\\mu\\) e se ne riportino gli estremi nel seguente riquadro.\n\n\n\nSoluzione\ny &lt;- c(17.6, 8.3, 12.7, 14, 12.9, 10.5, 18.2)\n\nalpha &lt;- .02\nn &lt;- length(y)\n\nmean(y) + c(-1,1)*qt(1-alpha/2, n-1)*sqrt(var(y)/length(y))\n\n\n\nSi implementi uno studio di simulazione atto a verificare empiricamente che, costruendo intervalli di confidenza al 95% per \\(\\mu\\) con la precedente formula, il 95% degli intervalli costruiti contiene il vero valore del parametro, mentre il restante 5% no. Si basi la simulazione su \\(B = 10'000\\) repliche e campioni di ampiezza \\(n=100\\); si considerino inoltre i valori \\(\\mu = 11\\) e \\(\\sigma^2 = 23\\) come veri valori dei parametri. Si imposti il proprio numero di matricola come seme (seed).\n\n\n\nSoluzione\nset.seed(42)\n\nB &lt;- 10000\ncoverage &lt;- numeric(B)\n\nn &lt;- 100\nmu_true &lt;- 11\nvar_true &lt;- 23\n\nalpha &lt;- 0.05\n\nfor(b in 1:B){\n  y &lt;- rnorm(n, mu_true, sqrt(var_true))\n  IC &lt;- mean(y) + c(-1,1)*qt(1-alpha/2, n-1)*sqrt(var(y)/n)\n  \n  coverage[b] &lt;- IC[2] &gt;= mu_true & IC[1] &lt;= mu_true\n}\n\nmean(coverage)\n\n\n\nSi implementi uno studio di simulazione basato su \\(B = 5'000\\) repliche per studiare la lunghezza media degli intervalli di confidenza per \\(\\mu\\) a livello 95% su campioni di ampiezza crescente, considerando \\(n \\in \\{10, 20, 50, 100\\}\\). Si rappresenti graficamente la relazione tra \\(n\\) e la lunghezza media dell’intervallo.\n\n\n\nSoluzione\nB &lt;- 5000\nn_vec &lt;- c(10, 20, 50, 100)\nlunghezza &lt;- matrix(NA, ncol = length(n_vec), nrow = B)\n\nalpha &lt;- 0.05\n\nfor(b in 1:B){\n  for(nn in 1:length(n_vec)){\n    n &lt;- n_vec[nn]\n    \n    y &lt;- rnorm(n, mu_true, sqrt(var_true))\n    IC &lt;- mean(y) + c(-1,1)*qt(1-alpha/2, n-1)*sqrt(var(y)/n)\n    \n    lunghezza[b, nn] &lt;- IC[2] - IC[1]\n  }\n}\n\nplot(n_vec, colMeans(lunghezza))\n\n\n\nSi implementi uno studio di simulazione basato su \\(B = 5'000\\) repliche per studiare la lunghezza media degli intervalli di confidenza per \\(\\mu\\) su campioni di ampiezza \\(n=100\\) considerando i seguenti livelli di confidenza \\(1-\\alpha \\in \\{0.85, 0.9, 0.95, 0.99\\}\\). Si rappresenti graficamente la relazione tra \\(1-\\alpha\\) e la lunghezza media dell’intervallo.\n\n\n\nSoluzione\nB &lt;- 5000\nconf_vec &lt;- c(.85, .9, .95, .99)\nlunghezza &lt;- matrix(NA, ncol = length(conf_vec), nrow = B)\n\nn &lt;- 100\n\nfor(b in 1:B){\n  for(aa in 1:length(conf_vec)){\n    alpha &lt;- 1-conf_vec[aa]\n\n    y &lt;- rnorm(n, mu_true, sqrt(var_true))\n    IC &lt;- mean(y) + c(-1,1)*qt(1-alpha/2, n-1)*sqrt(var(y)/n)\n    \n    lunghezza[b, aa] &lt;- IC[2] - IC[1]\n  }\n}\n\nplot(conf_vec, colMeans(lunghezza))"
  }
]